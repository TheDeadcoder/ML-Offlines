{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 60000\n",
      "Number of test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "train_data_path = 'data/train.csv'\n",
    "test_data_path = 'data/test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "print(\"Number of training examples:\", train_data.shape[0])\n",
    "print(\"Number of test examples:\", test_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# Separate features and labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop('label', axis=1).values\n",
    "y_train = train_data['label'].values\n",
    "\n",
    "X_test = test_data.drop('label', axis=1).values\n",
    "y_test = test_data['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize the pixel values (scale to [0, 1])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert labels to one-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "num_classes = 10\n",
    "y_train_one_hot = one_hot_encode(y_train, num_classes)\n",
    "y_test_one_hot = one_hot_encode(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the training data into training and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train_one_hot, y_val_one_hot = train_test_split(\n",
    "    X_train, y_train_one_hot, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Neural Network Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dense Layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "\n",
    "### Initialization:\n",
    "- **Weights (`self.w`):**\n",
    "  - Initialized with a scaled random normal distribution.\n",
    "  - `np.sqrt(2.0 / input_dim)`: He initialization, suitable for ReLU activations.\n",
    "\n",
    "- **Biases (`self.b`):**\n",
    "  - Initialized to zeros.\n",
    "\n",
    "- **Gradients (`self.dw`, `self.db`):**\n",
    "  - Placeholders for gradients computed during backpropagation.\n",
    "\n",
    "### Adam Parameters:\n",
    "- **First Moment Vectors (`self.m_w`, `self.m_b`):**\n",
    "  - Moving averages of the gradients.\n",
    "\n",
    "- **Second Moment Vectors (`self.v_w`, `self.v_b`):**\n",
    "  - Moving averages of the squared gradients.\n",
    "\n",
    "### Cache (`self.input`):\n",
    "- Stores the input to the layer for use during backpropagation.\n",
    "\n",
    "## Theory:\n",
    "\n",
    "### Dense (Fully Connected) Layer:\n",
    "- Each neuron receives input from all neurons in the previous layer.\n",
    "- Computes `output = X * W + b`.\n",
    "\n",
    "### He Initialization:\n",
    "- Addresses the problem of vanishing/exploding gradients.\n",
    "- Suitable for layers followed by ReLU activation.\n",
    "\n",
    "\n",
    "### **Forward Pass Explanation:**\n",
    "  - Computes the linear transformation.\n",
    "  - Stores the input \\( X \\) for use in backpropagation.\n",
    "\n",
    "**Mathematical Operation:**\n",
    "  -  `output = X * W + b`.\n",
    "\n",
    "### **Backward Pass Explanation**:\n",
    "\n",
    "- **Gradients w.r.t Weights (`self.dw`):**\n",
    "  - Computed as the dot product of the transposed input and `grad_output`.\n",
    "\n",
    "- **Gradients w.r.t Biases (`self.db`):**\n",
    "  - Sum of `grad_output` along the batch dimension.\n",
    "\n",
    "- **Gradient w.r.t Input (`grad_input`):**\n",
    "  - Propagated backward to previous layers.\n",
    "  - Computed as the dot product of `grad_output` and transposed weights.\n",
    "\n",
    "## Theory:\n",
    "- Backpropagation involves computing the gradients of the loss with respect to each parameter.\n",
    "- Uses the chain rule from calculus.\n",
    "\n",
    "**Explanation for updating parameters:**\n",
    "  - **Computing Moving Averages:**\n",
    "    - `self.m_w`, `self.m_b`: Exponential moving averages of gradients (first moment).\n",
    "    - `self.v_w`, `self.v_b`: Exponential moving averages of squared gradients (second moment).\n",
    "  \n",
    "  - **Bias Correction:**\n",
    "    - Adjusts the moments to account for their initialization at zero.\n",
    "    - `m_w_hat`, `v_w_hat`: Corrected moments.\n",
    "\n",
    "  - **Parameter Updates:**\n",
    "    - Updates weights and biases using the Adam update rule.\n",
    "\n",
    "# Parameter Update Theory:\n",
    "\n",
    "- **Adam Optimizer:**\n",
    "  - Combines the advantages of both AdaGrad and RMSProp.\n",
    "\n",
    "  - **First Moment Estimate (Mean):**\n",
    "    - \\( m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\)\n",
    "\n",
    "  - **Second Moment Estimate (Variance):**\n",
    "    - \\( v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 \\)\n",
    "\n",
    "  - **Bias Correction:**\n",
    "    - Adjusts for the initial bias towards zero moments.\n",
    "\n",
    "  - **Parameter Update:**\n",
    "    - \\( \\theta_t = \\theta_{t-1} - \\alpha \\frac{m_t}{\\sqrt{v_t} + \\epsilon} \\)\n",
    "\n",
    "- **Parameters:**\n",
    "  - `beta1` and `beta2`:\n",
    "    - Hyperparameters controlling the decay rates of the moving averages.\n",
    "    - Commonly set to `beta1=0.9` and `beta2=0.999`.\n",
    "\n",
    "  - `epsilon`:\n",
    "    - Small constant to prevent division by zero.\n",
    "\n",
    "  - `t`:\n",
    "    - Timestep, incremented after each parameter update.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        # Initialize weights and biases\n",
    "        self.W = np.random.randn(input_dim, output_dim) * np.sqrt(2.0 / input_dim)\n",
    "        self.b = np.zeros((1, output_dim))\n",
    "        \n",
    "        # Gradients\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "        # Adam parameters\n",
    "        self.m_W = np.zeros_like(self.W)\n",
    "        self.v_W = np.zeros_like(self.W)\n",
    "        self.m_b = np.zeros_like(self.b)\n",
    "        self.v_b = np.zeros_like(self.b)\n",
    "        \n",
    "        # Cache for backpropagation\n",
    "        self.input = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.input = X\n",
    "        output = np.dot(X, self.W) + self.b\n",
    "        return output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        # Compute gradients\n",
    "        self.dW = np.dot(self.input.T, grad_output)\n",
    "        self.db = np.sum(grad_output, axis=0, keepdims=True)\n",
    "        grad_input = np.dot(grad_output, self.W.T)\n",
    "        return grad_input\n",
    "    \n",
    "    def update_params(self, learning_rate, beta1, beta2, epsilon, t):\n",
    "        # Update weights and biases using Adam optimizer\n",
    "        self.m_W = beta1 * self.m_W + (1 - beta1) * self.dW\n",
    "        self.v_W = beta2 * self.v_W + (1 - beta2) * (self.dW ** 2)\n",
    "        m_W_hat = self.m_W / (1 - beta1 ** t)\n",
    "        v_W_hat = self.v_W / (1 - beta2 ** t)\n",
    "        self.W -= learning_rate * m_W_hat / (np.sqrt(v_W_hat) + epsilon)\n",
    "        \n",
    "        self.m_b = beta1 * self.m_b + (1 - beta1) * self.db\n",
    "        self.v_b = beta2 * self.v_b + (1 - beta2) * (self.db ** 2)\n",
    "        m_b_hat = self.m_b / (1 - beta1 ** t)\n",
    "        v_b_hat = self.v_b / (1 - beta2 ** t)\n",
    "        self.b -= learning_rate * m_b_hat / (np.sqrt(v_b_hat) + epsilon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Scale Parameter (`self.gamma`):**\n",
    "  - Learns how much to scale the normalized output.\n",
    "\n",
    "- **Shift Parameter (`self.beta`):**\n",
    "  - Learns how much to shift the normalized output.\n",
    "\n",
    "- **`epsilon`:**\n",
    "  - Small constant to prevent division by zero.\n",
    "\n",
    "- **`momentum`:**\n",
    "  - Controls the updating of running estimates.\n",
    "\n",
    "- **Running Estimates:**\n",
    "  - `self.running_mean` and `self.running_var`:\n",
    "    - Used during inference to normalize data with global statistics.\n",
    "\n",
    "- **Gradients and Caches:**\n",
    "  - **Gradients (`self.dgamma`, `self.dbeta`):**\n",
    "    - For updating `gamma` and `beta`.\n",
    "  \n",
    "  - **Caches:**\n",
    "    - Stores intermediate variables needed for backpropagation.\n",
    "\n",
    "- **Adam Parameters:**\n",
    "  - For optimizing `gamma` and `beta`.\n",
    "\n",
    "\n",
    "## Batch Normalization:\n",
    "- Normalizes the input of each mini-batch to have zero mean and unit variance.\n",
    "- Helps in stabilizing the learning process and allows for higher learning rates.\n",
    "- Learns `gamma` and `beta` to restore the representation power.\n",
    "\n",
    "### Forward Pass:\n",
    "**Explanation:**\n",
    "  - **Training Mode:**\n",
    "    - **Compute Batch Statistics:**\n",
    "      - Mean (`self.batch_mean`) and variance (`self.batch_var`) over the mini-batch.\n",
    "      \n",
    "    - **Normalize the Batch:**\n",
    "      - Subtract mean and divide by standard deviation (`self.std_inv`).\n",
    "      \n",
    "    - **Scale and Shift:**\n",
    "      - Apply learned `gamma` and `beta`.\n",
    "      \n",
    "    - **Update Running Estimates:**\n",
    "      - For use during inference.\n",
    "\n",
    "  - **Inference Mode:**\n",
    "    - Uses the running mean and variance to normalize data.\n",
    "\n",
    "**Theory:**\n",
    "  - **Normalization Formula:**\n",
    "    - \\( \\hat{X} = \\frac{X - \\mu_{\\text{batch}}}{\\sqrt{\\sigma_{\\text{batch}}^2 + \\epsilon}} \\)\n",
    "\n",
    "  - **Scale and Shift:**\n",
    "    - \\( Y = \\gamma \\hat{X} + \\beta \\)\n",
    "\n",
    "  - **Running Estimates:**\n",
    "    - \\( \\text{running\\_mean} = \\text{momentum} \\times \\text{running\\_mean} + (1 - \\text{momentum}) \\times \\mu_{\\text{batch}} \\)\n",
    "    - Similar for running variance.\n",
    "\n",
    "## backward Pass\n",
    "- **Explanation:**\n",
    "  - **Gradients w.r.t Parameters:**\n",
    "    - `self.dgamma`:\n",
    "      - Gradient of the loss with respect to `gamma`.\n",
    "    - `self.dbeta`:\n",
    "      - Gradient of the loss with respect to `beta`.\n",
    "\n",
    "  - **Gradient w.r.t Input (`dX`):**\n",
    "    - Computed using chain rule and intermediate variables.\n",
    "    - Ensures that gradients flow correctly through the normalization step.\n",
    "\n",
    "- **Theory:**\n",
    "  - **Backpropagation Through Batch Norm:**\n",
    "    - Involves computing derivatives through the normalization and scaling steps.\n",
    "    - Requires careful calculation to maintain numerical stability.\n",
    "\n",
    "\n",
    "## update_params\n",
    "- Similar to the Dense Layer, but updates `gamma` and `beta` parameters.\n",
    "- Uses the Adam optimization algorithm for parameter updates.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization:\n",
    "    def __init__(self, input_dim, epsilon=1e-5, momentum=0.9):\n",
    "        self.gamma = np.ones((1, input_dim))\n",
    "        self.beta = np.zeros((1, input_dim))\n",
    "        self.epsilon = epsilon\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        self.running_mean = np.zeros((1, input_dim))\n",
    "        self.running_var = np.zeros((1, input_dim))\n",
    "        \n",
    "        # Gradients\n",
    "        self.dgamma = None\n",
    "        self.dbeta = None\n",
    "        \n",
    "        # Cache for backpropagation\n",
    "        self.X_centered = None\n",
    "        self.std_inv = None\n",
    "        self.batch_mean = None\n",
    "        self.batch_var = None\n",
    "        \n",
    "        # Adam parameters\n",
    "        self.m_gamma = np.zeros_like(self.gamma)\n",
    "        self.v_gamma = np.zeros_like(self.gamma)\n",
    "        self.m_beta = np.zeros_like(self.beta)\n",
    "        self.v_beta = np.zeros_like(self.beta)\n",
    "    \n",
    "    def forward(self, X, training=True):\n",
    "        if training:\n",
    "            self.batch_mean = np.mean(X, axis=0, keepdims=True)\n",
    "            self.batch_var = np.var(X, axis=0, keepdims=True)\n",
    "            \n",
    "            self.X_centered = X - self.batch_mean\n",
    "            self.std_inv = 1.0 / np.sqrt(self.batch_var + self.epsilon)\n",
    "            \n",
    "            X_norm = self.X_centered * self.std_inv\n",
    "            out = self.gamma * X_norm + self.beta\n",
    "            \n",
    "            # Update running estimates\n",
    "            self.running_mean = self.momentum * self.running_mean + (1 - self.momentum) * self.batch_mean\n",
    "            self.running_var = self.momentum * self.running_var + (1 - self.momentum) * self.batch_var\n",
    "        else:\n",
    "            # Use running mean and var during inference\n",
    "            X_centered = X - self.running_mean\n",
    "            std_inv = 1.0 / np.sqrt(self.running_var + self.epsilon)\n",
    "            X_norm = X_centered * std_inv\n",
    "            out = self.gamma * X_norm + self.beta\n",
    "        return out\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        N, D = grad_output.shape\n",
    "        \n",
    "        # Step-wise computation for gradients\n",
    "        X_norm = self.X_centered * self.std_inv\n",
    "        dX_norm = grad_output * self.gamma\n",
    "        \n",
    "        dvar = np.sum(dX_norm * self.X_centered * -0.5 * self.std_inv ** 3, axis=0)\n",
    "        dmean = np.sum(dX_norm * -self.std_inv, axis=0) + dvar * np.mean(-2.0 * self.X_centered, axis=0)\n",
    "        \n",
    "        dX = (dX_norm * self.std_inv) + (dvar * 2.0 * self.X_centered / N) + (dmean / N)\n",
    "        self.dgamma = np.sum(grad_output * X_norm, axis=0, keepdims=True)\n",
    "        self.dbeta = np.sum(grad_output, axis=0, keepdims=True)\n",
    "        \n",
    "        return dX\n",
    "    \n",
    "    def update_params(self, learning_rate, beta1, beta2, epsilon, t):\n",
    "        # Update gamma and beta using Adam optimizer\n",
    "        self.m_gamma = beta1 * self.m_gamma + (1 - beta1) * self.dgamma\n",
    "        self.v_gamma = beta2 * self.v_gamma + (1 - beta2) * (self.dgamma ** 2)\n",
    "        m_gamma_hat = self.m_gamma / (1 - beta1 ** t)\n",
    "        v_gamma_hat = self.v_gamma / (1 - beta2 ** t)\n",
    "        self.gamma -= learning_rate * m_gamma_hat / (np.sqrt(v_gamma_hat) + epsilon)\n",
    "        \n",
    "        self.m_beta = beta1 * self.m_beta + (1 - beta1) * self.dbeta\n",
    "        self.v_beta = beta2 * self.v_beta + (1 - beta2) * (self.dbeta ** 2)\n",
    "        m_beta_hat = self.m_beta / (1 - beta1 ** t)\n",
    "        v_beta_hat = self.v_beta / (1 - beta2 ** t)\n",
    "        self.beta -= learning_rate * m_beta_hat / (np.sqrt(v_beta_hat) + epsilon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ReLU Activation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU Activation\n",
    "- **Forward Pass:**\n",
    "  - `np.maximum(0, X)`:\n",
    "    - Applies the ReLU function element-wise.\n",
    "    - Sets all negative inputs to zero.\n",
    "\n",
    "- **Backward Pass:**\n",
    "  - **Gradient w.r.t Input (`grad_input`):**\n",
    "    - For inputs where \\( X > 0 \\), gradient is unchanged.\n",
    "    - For inputs where \\( X \\leq 0 \\), gradient is zero.\n",
    "\n",
    "- **Theory:**\n",
    "  - **ReLU Function:**\n",
    "    - \\( \\text{ReLU}(x) = \\max(0, x) \\)\n",
    "\n",
    "  - **Derivative:**\n",
    "    - \\( \\frac{d}{dx} \\text{ReLU}(x) = \\begin{cases} 1, & x > 0 \\\\ 0, & x \\leq 0 \\end{cases} \\)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.input = X\n",
    "        return np.maximum(0, X)\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        grad_input = grad_output.copy()\n",
    "        grad_input[self.input <= 0] = 0\n",
    "        return grad_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "- Regularization technique to prevent overfitting.\n",
    "- During training, randomly drops units along with their connections.\n",
    "- **Scaling**:\n",
    "- - By scaling the activations during training, there's no need to adjust them during inference.\n",
    "- **Parameters:**\n",
    "  - `dropout_rate`:\n",
    "    - Probability of dropping a neuron (setting its output to zero).\n",
    "\n",
    "- **Forward Pass:**\n",
    "  - **Training Mode:**\n",
    "    - **Creating the Mask:**\n",
    "      - Randomly sets neurons to zero with probability `dropout_rate`.\n",
    "      - **Scaling:** Divides by \\( (1 - \\text{dropout_rate}) \\) to keep the expected value of the activations the same.\n",
    "      \n",
    "    - **Applying the Mask:**\n",
    "      - Multiplies the input \\( X \\) by the mask.\n",
    "\n",
    "  - **Inference Mode:**\n",
    "    - No dropout is applied during testing.\n",
    "\n",
    "- **Backward Pass:**\n",
    "  - **Gradient w.r.t Input (`grad_output * self.mask`):**\n",
    "    - Propagates gradients only through the neurons that were not dropped during the forward pass.\n",
    "- **Scaling**\n",
    "  By scaling the activations during training, there's no need to adjust them during inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, dropout_rate):\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.mask = None\n",
    "    \n",
    "    def forward(self, X, training=True):\n",
    "        if training:\n",
    "            self.mask = (np.random.rand(*X.shape) > self.dropout_rate) / (1.0 - self.dropout_rate)\n",
    "            return X * self.mask\n",
    "        else:\n",
    "            return X  # During inference, no dropout applied\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax and Cross-Entropy Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_entropy_loss(logits, labels):\n",
    "    # logits: output of the network before softmax, shape (N, C)\n",
    "    # labels: one-hot encoded true labels, shape (N, C)\n",
    "    # returns loss and gradient with respect to logits\n",
    "    \n",
    "    # Compute softmax probabilities\n",
    "    exps = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    softmax_probs = exps / np.sum(exps, axis=1, keepdims=True)\n",
    "    \n",
    "    # Compute loss\n",
    "    N = logits.shape[0]\n",
    "    loss = -np.sum(labels * np.log(softmax_probs + 1e-15)) / N\n",
    "    \n",
    "    # Compute gradient\n",
    "    grad_logits = (softmax_probs - labels) / N\n",
    "    return loss, grad_logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization:\n",
    "- self.layers:\n",
    "  - List of layers constituting the network.\n",
    "- self.t:\n",
    "  - Global timestep used for Adam optimizer.\n",
    "\n",
    "### Forward Pass:\n",
    "- Iterates through each layer, passing the output of one as the input to the next.\n",
    "- **Conditional Forward Pass:**: For layers that behave differently during training and inference (Dropout, BatchNormalization), passes the training flag.\n",
    "\n",
    "### Backward Pass:\n",
    "- Iterates through layers in reverse order.\n",
    "- Passes the gradient from one layer to the previous.\n",
    "\n",
    "### Parameter Update:\n",
    "- Updates parameters of each layer that has an `update_params` method.\n",
    "- Increments the global timestep `self.t` after each update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.t = 1  # Timestep for Adam optimizer\n",
    "    \n",
    "    def forward(self, X, training=True):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, (Dropout, BatchNormalization)):\n",
    "                X = layer.forward(X, training=training)\n",
    "            else:\n",
    "                X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        for layer in reversed(self.layers):\n",
    "            grad_output = layer.backward(grad_output)\n",
    "    \n",
    "    def update_params(self, learning_rate, beta1, beta2, epsilon):\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'update_params'):\n",
    "                layer.update_params(learning_rate, beta1, beta2, epsilon, self.t)\n",
    "        self.t += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Structure:\n",
    "- Input Layer: Receives flattened 28x28 images `(input_dim = 784)`.\n",
    "  \n",
    "### First Hidden Layer:\n",
    "- Dense Layer: 512 units. \n",
    "- Batch Normalization.\n",
    "- ReLU Activation.\n",
    "- Dropout with 30% rate.\n",
    "\n",
    "### Second Hidden Layer:\n",
    "- Dense Layer: 256 units. \n",
    "- Batch Normalization.\n",
    "- ReLU Activation.\n",
    "- Dropout with 30% rate.\n",
    "\n",
    "### Third Hidden Layer:\n",
    "- Dense Layer: 128 units. \n",
    "- Batch Normalization.\n",
    "- ReLU Activation.\n",
    "- Dropout with 30% rate.\n",
    "\n",
    "### Output Layer\n",
    "- Dense Layer: 10 units (one for each class).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = {\n",
    "    'Arch1': {\n",
    "        'layers': [\n",
    "            {'units': 512},\n",
    "            {'units': 256},\n",
    "            {'units': 128},\n",
    "        ],\n",
    "    },\n",
    "    'Arch2': {\n",
    "        'layers': [\n",
    "            {'units': 1024},\n",
    "            {'units': 512},\n",
    "            {'units': 256},\n",
    "            {'units': 128},\n",
    "        ],\n",
    "    },\n",
    "    'Arch3': {\n",
    "        'layers': [\n",
    "            {'units': 256},\n",
    "            {'units': 128},\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting Hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Learning Rate (`learning_rate`):**\n",
    "  - Step size for parameter updates.\n",
    "\n",
    "- **Adam Hyperparameters:**\n",
    "  - `beta1`: Decay rate for first moment estimates.\n",
    "  - `beta2`: Decay rate for second moment estimates.\n",
    "  - `epsilon`: Small constant to prevent division by zero.\n",
    "\n",
    "- **Training Configuration:**\n",
    "  - `num_epochs`: Number of times the entire training dataset is passed through the network.\n",
    "  - `batch_size`: Number of samples processed before updating the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "epsilon = 1e-8\n",
    "num_epochs = 25  \n",
    "batch_size = 64\n",
    "dropout_rate = 0.3 \n",
    "learning_rates = [0.005, 0.001, 0.0009, 0.0006]\n",
    "\n",
    "best_test_accuracy = 0.0\n",
    "best_model = None\n",
    "best_model_info = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, X_train, y_train_one_hot, X_val, y_val_one_hot, num_epochs, batch_size, learning_rate):\n",
    "    num_train_samples = X_train.shape[0]\n",
    "    num_batches = int(np.ceil(num_train_samples / batch_size))\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_f1s = []\n",
    "    val_f1s = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the training data\n",
    "        indices = np.arange(num_train_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        X_train_shuffled = X_train[indices]\n",
    "        y_train_shuffled = y_train_one_hot[indices]\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        all_predictions = []\n",
    "        all_true_labels = []\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            start = i * batch_size\n",
    "            end = min(start + batch_size, num_train_samples)\n",
    "            X_batch = X_train_shuffled[start:end]\n",
    "            y_batch = y_train_shuffled[start:end]\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = network.forward(X_batch, training=True)\n",
    "            \n",
    "            # Compute loss and gradient\n",
    "            loss, grad_logits = softmax_cross_entropy_loss(logits, y_batch)\n",
    "            epoch_loss += loss\n",
    "            \n",
    "            # Backward pass\n",
    "            network.backward(grad_logits)\n",
    "            \n",
    "            # Update parameters\n",
    "            network.update_params(learning_rate, beta1, beta2, epsilon)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            predictions = np.argmax(logits, axis=1)\n",
    "            true_labels = np.argmax(y_batch, axis=1)\n",
    "            correct_predictions += np.sum(predictions == true_labels)\n",
    "            total_samples += predictions.shape[0]\n",
    "            \n",
    "            all_predictions.extend(predictions)\n",
    "            all_true_labels.extend(true_labels)\n",
    "        \n",
    "        # Compute average training loss and accuracy\n",
    "        avg_train_loss = epoch_loss / num_batches\n",
    "        train_accuracy = correct_predictions / total_samples\n",
    "        train_f1 = f1_score(all_true_labels, all_predictions, average='macro')\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_f1s.append(train_f1)\n",
    "        \n",
    "        # Validation\n",
    "        logits_val = network.forward(X_val, training=False)\n",
    "        val_loss, _ = softmax_cross_entropy_loss(logits_val, y_val_one_hot)\n",
    "        \n",
    "        predictions_val = np.argmax(logits_val, axis=1)\n",
    "        true_labels_val = np.argmax(y_val_one_hot, axis=1)\n",
    "        val_accuracy = np.mean(predictions_val == true_labels_val)\n",
    "        val_f1 = f1_score(true_labels_val, predictions_val, average='macro')\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_f1s.append(val_f1)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, \"\n",
    "              f\"Training Accuracy: {train_accuracy:.4f}, Training F1: {train_f1:.4f}, \"\n",
    "              f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, \"\n",
    "              f\"Validation F1: {val_f1:.4f}\")\n",
    "        \n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies, train_f1s, val_f1s\n",
    "\n",
    "def plot_metrics(arch_name, learning_rate, train_losses, val_losses,\n",
    "                 train_accuracies, val_accuracies, train_f1s, val_f1s):\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "    plt.title(f'Loss vs. Epochs ({arch_name}, Learning Rate: {learning_rate})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'loss_{arch_name}_lr_{learning_rate}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot Accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_accuracies, 'b-', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accuracies, 'r-', label='Validation Accuracy')\n",
    "    plt.title(f'Accuracy vs. Epochs ({arch_name}, Learning Rate: {learning_rate})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'accuracy_{arch_name}_lr_{learning_rate}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot F1 Score\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_f1s, 'b-', label='Training F1 Score')\n",
    "    plt.plot(epochs, val_f1s, 'r-', label='Validation F1 Score')\n",
    "    plt.title(f'F1 Score vs. Epochs ({arch_name}, Learning Rate: {learning_rate})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'f1_{arch_name}_lr_{learning_rate}.png')\n",
    "    plt.close()\n",
    "\n",
    "# def generate_confusion_matrix(network, X_test, y_test):\n",
    "#     logits = network.forward(X_test, training=False)\n",
    "#     predictions = np.argmax(logits, axis=1)\n",
    "    \n",
    "#     cm = confusion_matrix(y_test, predictions)\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "#                 xticklabels=range(10), yticklabels=range(10))\n",
    "#     plt.title('Confusion Matrix')\n",
    "#     plt.xlabel('Predicted Label')\n",
    "#     plt.ylabel('True Label')\n",
    "#     plt.savefig('confusion_matrix.png')\n",
    "#     plt.close()\n",
    "\n",
    "def generate_confusion_matrix(network, X_test, y_test, arch_name, learning_rate):\n",
    "    logits = network.forward(X_test, training=False)\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=range(10), yticklabels=range(10))\n",
    "    plt.title(f'Confusion Matrix - Architecture: {arch_name}, Learning Rate: {learning_rate}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    \n",
    "    # Save the confusion matrix with architecture and learning rate in the filename\n",
    "    filename = f'confusion_matrix_{arch_name}_lr_{learning_rate}.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(network, X_test, y_test_one_hot):\n",
    "    logits = network.forward(X_test, training=False)\n",
    "    test_loss, _ = softmax_cross_entropy_loss(logits, y_test_one_hot)\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    true_labels = np.argmax(y_test_one_hot, axis=1)\n",
    "    test_accuracy = np.mean(predictions == true_labels)\n",
    "    test_f1 = f1_score(true_labels, predictions, average='macro')\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}\")   \n",
    "    return test_loss, test_accuracy, test_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training models for architecture: Arch1\n",
      "  Training with learning rate: 0.005\n",
      "Epoch 1/25, Training Loss: 0.5565, Training Accuracy: 0.8008, Training F1: 0.7989, Validation Loss: 0.3970, Validation Accuracy: 0.8510, Validation F1: 0.8485\n",
      "Epoch 2/25, Training Loss: 0.4408, Training Accuracy: 0.8421, Training F1: 0.8410, Validation Loss: 0.3622, Validation Accuracy: 0.8670, Validation F1: 0.8634\n",
      "Epoch 3/25, Training Loss: 0.3984, Training Accuracy: 0.8577, Training F1: 0.8568, Validation Loss: 0.3399, Validation Accuracy: 0.8723, Validation F1: 0.8719\n",
      "Epoch 4/25, Training Loss: 0.3752, Training Accuracy: 0.8645, Training F1: 0.8635, Validation Loss: 0.3305, Validation Accuracy: 0.8748, Validation F1: 0.8781\n",
      "Epoch 5/25, Training Loss: 0.3566, Training Accuracy: 0.8719, Training F1: 0.8710, Validation Loss: 0.2986, Validation Accuracy: 0.8847, Validation F1: 0.8854\n",
      "Epoch 6/25, Training Loss: 0.3422, Training Accuracy: 0.8755, Training F1: 0.8747, Validation Loss: 0.3164, Validation Accuracy: 0.8837, Validation F1: 0.8833\n",
      "Epoch 7/25, Training Loss: 0.3307, Training Accuracy: 0.8799, Training F1: 0.8791, Validation Loss: 0.2940, Validation Accuracy: 0.8908, Validation F1: 0.8927\n",
      "Epoch 8/25, Training Loss: 0.3188, Training Accuracy: 0.8835, Training F1: 0.8828, Validation Loss: 0.2949, Validation Accuracy: 0.8930, Validation F1: 0.8940\n",
      "Epoch 9/25, Training Loss: 0.3073, Training Accuracy: 0.8885, Training F1: 0.8877, Validation Loss: 0.2954, Validation Accuracy: 0.8920, Validation F1: 0.8927\n",
      "Epoch 10/25, Training Loss: 0.2962, Training Accuracy: 0.8927, Training F1: 0.8921, Validation Loss: 0.2847, Validation Accuracy: 0.8988, Validation F1: 0.9004\n",
      "Epoch 11/25, Training Loss: 0.2864, Training Accuracy: 0.8937, Training F1: 0.8930, Validation Loss: 0.2833, Validation Accuracy: 0.8947, Validation F1: 0.8938\n",
      "Epoch 12/25, Training Loss: 0.2802, Training Accuracy: 0.8988, Training F1: 0.8982, Validation Loss: 0.2783, Validation Accuracy: 0.9005, Validation F1: 0.9012\n",
      "Epoch 13/25, Training Loss: 0.2727, Training Accuracy: 0.9000, Training F1: 0.8994, Validation Loss: 0.2892, Validation Accuracy: 0.8935, Validation F1: 0.8943\n",
      "Epoch 14/25, Training Loss: 0.2658, Training Accuracy: 0.9033, Training F1: 0.9027, Validation Loss: 0.2753, Validation Accuracy: 0.8995, Validation F1: 0.9008\n",
      "Epoch 15/25, Training Loss: 0.2612, Training Accuracy: 0.9053, Training F1: 0.9048, Validation Loss: 0.2765, Validation Accuracy: 0.8992, Validation F1: 0.8992\n",
      "Epoch 16/25, Training Loss: 0.2505, Training Accuracy: 0.9081, Training F1: 0.9076, Validation Loss: 0.2798, Validation Accuracy: 0.8948, Validation F1: 0.8961\n",
      "Epoch 17/25, Training Loss: 0.2453, Training Accuracy: 0.9086, Training F1: 0.9082, Validation Loss: 0.2920, Validation Accuracy: 0.8973, Validation F1: 0.8964\n",
      "Epoch 18/25, Training Loss: 0.2429, Training Accuracy: 0.9122, Training F1: 0.9117, Validation Loss: 0.2780, Validation Accuracy: 0.8987, Validation F1: 0.8987\n",
      "Epoch 19/25, Training Loss: 0.2349, Training Accuracy: 0.9134, Training F1: 0.9129, Validation Loss: 0.2803, Validation Accuracy: 0.8977, Validation F1: 0.8994\n",
      "Epoch 20/25, Training Loss: 0.2298, Training Accuracy: 0.9147, Training F1: 0.9143, Validation Loss: 0.2785, Validation Accuracy: 0.9010, Validation F1: 0.9022\n",
      "Epoch 21/25, Training Loss: 0.2255, Training Accuracy: 0.9172, Training F1: 0.9167, Validation Loss: 0.2909, Validation Accuracy: 0.8958, Validation F1: 0.8975\n",
      "Epoch 22/25, Training Loss: 0.2199, Training Accuracy: 0.9189, Training F1: 0.9184, Validation Loss: 0.2741, Validation Accuracy: 0.9007, Validation F1: 0.9013\n",
      "Epoch 23/25, Training Loss: 0.2169, Training Accuracy: 0.9202, Training F1: 0.9198, Validation Loss: 0.2797, Validation Accuracy: 0.9012, Validation F1: 0.9035\n",
      "Epoch 24/25, Training Loss: 0.2096, Training Accuracy: 0.9215, Training F1: 0.9211, Validation Loss: 0.2784, Validation Accuracy: 0.8980, Validation F1: 0.9000\n",
      "Epoch 25/25, Training Loss: 0.2087, Training Accuracy: 0.9226, Training F1: 0.9223, Validation Loss: 0.2789, Validation Accuracy: 0.9052, Validation F1: 0.9066\n",
      "Test Loss: 0.2767, Test Accuracy: 0.9042, Test F1 Score: 0.9042\n",
      "  Training with learning rate: 0.001\n",
      "Epoch 1/25, Training Loss: 0.5835, Training Accuracy: 0.7938, Training F1: 0.7922, Validation Loss: 0.3601, Validation Accuracy: 0.8662, Validation F1: 0.8662\n",
      "Epoch 2/25, Training Loss: 0.4285, Training Accuracy: 0.8452, Training F1: 0.8441, Validation Loss: 0.3354, Validation Accuracy: 0.8770, Validation F1: 0.8790\n",
      "Epoch 3/25, Training Loss: 0.3897, Training Accuracy: 0.8584, Training F1: 0.8575, Validation Loss: 0.3258, Validation Accuracy: 0.8767, Validation F1: 0.8777\n",
      "Epoch 4/25, Training Loss: 0.3674, Training Accuracy: 0.8662, Training F1: 0.8654, Validation Loss: 0.3411, Validation Accuracy: 0.8653, Validation F1: 0.8661\n",
      "Epoch 5/25, Training Loss: 0.3491, Training Accuracy: 0.8741, Training F1: 0.8732, Validation Loss: 0.2878, Validation Accuracy: 0.8903, Validation F1: 0.8918\n",
      "Epoch 6/25, Training Loss: 0.3320, Training Accuracy: 0.8789, Training F1: 0.8782, Validation Loss: 0.3150, Validation Accuracy: 0.8788, Validation F1: 0.8786\n",
      "Epoch 7/25, Training Loss: 0.3171, Training Accuracy: 0.8846, Training F1: 0.8839, Validation Loss: 0.2859, Validation Accuracy: 0.8888, Validation F1: 0.8907\n",
      "Epoch 8/25, Training Loss: 0.3056, Training Accuracy: 0.8880, Training F1: 0.8874, Validation Loss: 0.2767, Validation Accuracy: 0.8982, Validation F1: 0.8993\n",
      "Epoch 9/25, Training Loss: 0.2949, Training Accuracy: 0.8919, Training F1: 0.8912, Validation Loss: 0.2752, Validation Accuracy: 0.8978, Validation F1: 0.8989\n",
      "Epoch 10/25, Training Loss: 0.2867, Training Accuracy: 0.8939, Training F1: 0.8933, Validation Loss: 0.2913, Validation Accuracy: 0.8903, Validation F1: 0.8901\n",
      "Epoch 11/25, Training Loss: 0.2814, Training Accuracy: 0.8959, Training F1: 0.8953, Validation Loss: 0.2784, Validation Accuracy: 0.8930, Validation F1: 0.8945\n",
      "Epoch 12/25, Training Loss: 0.2700, Training Accuracy: 0.8994, Training F1: 0.8988, Validation Loss: 0.2849, Validation Accuracy: 0.8943, Validation F1: 0.8964\n",
      "Epoch 13/25, Training Loss: 0.2615, Training Accuracy: 0.9038, Training F1: 0.9033, Validation Loss: 0.2723, Validation Accuracy: 0.9013, Validation F1: 0.9029\n",
      "Epoch 14/25, Training Loss: 0.2562, Training Accuracy: 0.9045, Training F1: 0.9039, Validation Loss: 0.2903, Validation Accuracy: 0.8958, Validation F1: 0.8954\n",
      "Epoch 15/25, Training Loss: 0.2468, Training Accuracy: 0.9097, Training F1: 0.9092, Validation Loss: 0.2733, Validation Accuracy: 0.8965, Validation F1: 0.8983\n",
      "Epoch 16/25, Training Loss: 0.2382, Training Accuracy: 0.9121, Training F1: 0.9117, Validation Loss: 0.2725, Validation Accuracy: 0.8975, Validation F1: 0.8977\n",
      "Epoch 17/25, Training Loss: 0.2373, Training Accuracy: 0.9121, Training F1: 0.9116, Validation Loss: 0.2724, Validation Accuracy: 0.9008, Validation F1: 0.9007\n",
      "Epoch 18/25, Training Loss: 0.2293, Training Accuracy: 0.9147, Training F1: 0.9142, Validation Loss: 0.2737, Validation Accuracy: 0.8990, Validation F1: 0.9005\n",
      "Epoch 19/25, Training Loss: 0.2246, Training Accuracy: 0.9169, Training F1: 0.9165, Validation Loss: 0.2789, Validation Accuracy: 0.8962, Validation F1: 0.8974\n",
      "Epoch 20/25, Training Loss: 0.2202, Training Accuracy: 0.9171, Training F1: 0.9167, Validation Loss: 0.2711, Validation Accuracy: 0.9080, Validation F1: 0.9092\n",
      "Epoch 21/25, Training Loss: 0.2135, Training Accuracy: 0.9212, Training F1: 0.9209, Validation Loss: 0.2716, Validation Accuracy: 0.9017, Validation F1: 0.9031\n",
      "Epoch 22/25, Training Loss: 0.2086, Training Accuracy: 0.9235, Training F1: 0.9231, Validation Loss: 0.2674, Validation Accuracy: 0.9090, Validation F1: 0.9098\n",
      "Epoch 23/25, Training Loss: 0.2076, Training Accuracy: 0.9249, Training F1: 0.9245, Validation Loss: 0.2676, Validation Accuracy: 0.9030, Validation F1: 0.9044\n",
      "Epoch 24/25, Training Loss: 0.2050, Training Accuracy: 0.9244, Training F1: 0.9240, Validation Loss: 0.2762, Validation Accuracy: 0.9042, Validation F1: 0.9058\n",
      "Epoch 25/25, Training Loss: 0.1976, Training Accuracy: 0.9259, Training F1: 0.9255, Validation Loss: 0.2687, Validation Accuracy: 0.9023, Validation F1: 0.9039\n",
      "Test Loss: 0.2744, Test Accuracy: 0.9047, Test F1 Score: 0.9050\n",
      "  Training with learning rate: 0.0009\n",
      "Epoch 1/25, Training Loss: 0.5883, Training Accuracy: 0.7937, Training F1: 0.7918, Validation Loss: 0.3738, Validation Accuracy: 0.8612, Validation F1: 0.8623\n",
      "Epoch 2/25, Training Loss: 0.4361, Training Accuracy: 0.8431, Training F1: 0.8420, Validation Loss: 0.3440, Validation Accuracy: 0.8745, Validation F1: 0.8736\n",
      "Epoch 3/25, Training Loss: 0.3900, Training Accuracy: 0.8598, Training F1: 0.8588, Validation Loss: 0.3226, Validation Accuracy: 0.8803, Validation F1: 0.8822\n",
      "Epoch 4/25, Training Loss: 0.3656, Training Accuracy: 0.8681, Training F1: 0.8673, Validation Loss: 0.3230, Validation Accuracy: 0.8768, Validation F1: 0.8785\n",
      "Epoch 5/25, Training Loss: 0.3499, Training Accuracy: 0.8736, Training F1: 0.8727, Validation Loss: 0.3127, Validation Accuracy: 0.8832, Validation F1: 0.8824\n",
      "Epoch 6/25, Training Loss: 0.3330, Training Accuracy: 0.8796, Training F1: 0.8788, Validation Loss: 0.3101, Validation Accuracy: 0.8835, Validation F1: 0.8853\n",
      "Epoch 7/25, Training Loss: 0.3171, Training Accuracy: 0.8842, Training F1: 0.8835, Validation Loss: 0.2935, Validation Accuracy: 0.8920, Validation F1: 0.8924\n",
      "Epoch 8/25, Training Loss: 0.3069, Training Accuracy: 0.8869, Training F1: 0.8862, Validation Loss: 0.2858, Validation Accuracy: 0.8927, Validation F1: 0.8935\n",
      "Epoch 9/25, Training Loss: 0.2990, Training Accuracy: 0.8905, Training F1: 0.8899, Validation Loss: 0.2896, Validation Accuracy: 0.8915, Validation F1: 0.8934\n",
      "Epoch 10/25, Training Loss: 0.2847, Training Accuracy: 0.8961, Training F1: 0.8955, Validation Loss: 0.2803, Validation Accuracy: 0.8960, Validation F1: 0.8977\n",
      "Epoch 11/25, Training Loss: 0.2774, Training Accuracy: 0.8983, Training F1: 0.8978, Validation Loss: 0.2947, Validation Accuracy: 0.8913, Validation F1: 0.8917\n",
      "Epoch 12/25, Training Loss: 0.2685, Training Accuracy: 0.9004, Training F1: 0.8998, Validation Loss: 0.2870, Validation Accuracy: 0.8965, Validation F1: 0.8972\n",
      "Epoch 13/25, Training Loss: 0.2617, Training Accuracy: 0.9023, Training F1: 0.9017, Validation Loss: 0.2816, Validation Accuracy: 0.8978, Validation F1: 0.8997\n",
      "Epoch 14/25, Training Loss: 0.2523, Training Accuracy: 0.9063, Training F1: 0.9058, Validation Loss: 0.2823, Validation Accuracy: 0.8953, Validation F1: 0.8955\n",
      "Epoch 15/25, Training Loss: 0.2512, Training Accuracy: 0.9072, Training F1: 0.9066, Validation Loss: 0.2739, Validation Accuracy: 0.9023, Validation F1: 0.9031\n",
      "Epoch 16/25, Training Loss: 0.2424, Training Accuracy: 0.9105, Training F1: 0.9099, Validation Loss: 0.2929, Validation Accuracy: 0.8862, Validation F1: 0.8884\n",
      "Epoch 17/25, Training Loss: 0.2347, Training Accuracy: 0.9120, Training F1: 0.9115, Validation Loss: 0.2739, Validation Accuracy: 0.8997, Validation F1: 0.9009\n",
      "Epoch 18/25, Training Loss: 0.2300, Training Accuracy: 0.9156, Training F1: 0.9152, Validation Loss: 0.2699, Validation Accuracy: 0.9010, Validation F1: 0.9027\n",
      "Epoch 19/25, Training Loss: 0.2273, Training Accuracy: 0.9167, Training F1: 0.9163, Validation Loss: 0.2733, Validation Accuracy: 0.9022, Validation F1: 0.9030\n",
      "Epoch 20/25, Training Loss: 0.2215, Training Accuracy: 0.9175, Training F1: 0.9171, Validation Loss: 0.2794, Validation Accuracy: 0.9003, Validation F1: 0.9018\n",
      "Epoch 21/25, Training Loss: 0.2184, Training Accuracy: 0.9190, Training F1: 0.9186, Validation Loss: 0.2830, Validation Accuracy: 0.8985, Validation F1: 0.9001\n",
      "Epoch 22/25, Training Loss: 0.2071, Training Accuracy: 0.9240, Training F1: 0.9236, Validation Loss: 0.2787, Validation Accuracy: 0.9003, Validation F1: 0.9009\n",
      "Epoch 23/25, Training Loss: 0.2055, Training Accuracy: 0.9239, Training F1: 0.9235, Validation Loss: 0.2839, Validation Accuracy: 0.8997, Validation F1: 0.9006\n",
      "Epoch 24/25, Training Loss: 0.2039, Training Accuracy: 0.9241, Training F1: 0.9238, Validation Loss: 0.2753, Validation Accuracy: 0.9017, Validation F1: 0.9035\n",
      "Epoch 25/25, Training Loss: 0.1975, Training Accuracy: 0.9272, Training F1: 0.9268, Validation Loss: 0.2925, Validation Accuracy: 0.9020, Validation F1: 0.9035\n",
      "Test Loss: 0.2808, Test Accuracy: 0.9030, Test F1 Score: 0.9030\n",
      "  Training with learning rate: 0.0006\n",
      "Epoch 1/25, Training Loss: 0.6285, Training Accuracy: 0.7806, Training F1: 0.7788, Validation Loss: 0.3802, Validation Accuracy: 0.8572, Validation F1: 0.8543\n",
      "Epoch 2/25, Training Loss: 0.4451, Training Accuracy: 0.8411, Training F1: 0.8399, Validation Loss: 0.3638, Validation Accuracy: 0.8642, Validation F1: 0.8664\n",
      "Epoch 3/25, Training Loss: 0.4017, Training Accuracy: 0.8554, Training F1: 0.8544, Validation Loss: 0.3261, Validation Accuracy: 0.8785, Validation F1: 0.8792\n",
      "Epoch 4/25, Training Loss: 0.3713, Training Accuracy: 0.8659, Training F1: 0.8650, Validation Loss: 0.3187, Validation Accuracy: 0.8843, Validation F1: 0.8831\n",
      "Epoch 5/25, Training Loss: 0.3499, Training Accuracy: 0.8729, Training F1: 0.8720, Validation Loss: 0.3041, Validation Accuracy: 0.8840, Validation F1: 0.8853\n",
      "Epoch 6/25, Training Loss: 0.3367, Training Accuracy: 0.8774, Training F1: 0.8765, Validation Loss: 0.2929, Validation Accuracy: 0.8888, Validation F1: 0.8899\n",
      "Epoch 7/25, Training Loss: 0.3246, Training Accuracy: 0.8819, Training F1: 0.8813, Validation Loss: 0.2962, Validation Accuracy: 0.8873, Validation F1: 0.8898\n",
      "Epoch 8/25, Training Loss: 0.3135, Training Accuracy: 0.8855, Training F1: 0.8848, Validation Loss: 0.2918, Validation Accuracy: 0.8918, Validation F1: 0.8927\n",
      "Epoch 9/25, Training Loss: 0.2984, Training Accuracy: 0.8891, Training F1: 0.8885, Validation Loss: 0.2802, Validation Accuracy: 0.8965, Validation F1: 0.8965\n",
      "Epoch 10/25, Training Loss: 0.2899, Training Accuracy: 0.8929, Training F1: 0.8923, Validation Loss: 0.2789, Validation Accuracy: 0.8950, Validation F1: 0.8967\n",
      "Epoch 11/25, Training Loss: 0.2800, Training Accuracy: 0.8970, Training F1: 0.8964, Validation Loss: 0.2983, Validation Accuracy: 0.8912, Validation F1: 0.8934\n",
      "Epoch 12/25, Training Loss: 0.2735, Training Accuracy: 0.8985, Training F1: 0.8979, Validation Loss: 0.2764, Validation Accuracy: 0.8933, Validation F1: 0.8950\n",
      "Epoch 13/25, Training Loss: 0.2658, Training Accuracy: 0.9023, Training F1: 0.9017, Validation Loss: 0.2898, Validation Accuracy: 0.8922, Validation F1: 0.8921\n",
      "Epoch 14/25, Training Loss: 0.2614, Training Accuracy: 0.9045, Training F1: 0.9040, Validation Loss: 0.2732, Validation Accuracy: 0.8993, Validation F1: 0.9004\n",
      "Epoch 15/25, Training Loss: 0.2495, Training Accuracy: 0.9070, Training F1: 0.9064, Validation Loss: 0.2664, Validation Accuracy: 0.8995, Validation F1: 0.9007\n",
      "Epoch 16/25, Training Loss: 0.2445, Training Accuracy: 0.9081, Training F1: 0.9076, Validation Loss: 0.2685, Validation Accuracy: 0.8962, Validation F1: 0.8971\n",
      "Epoch 17/25, Training Loss: 0.2365, Training Accuracy: 0.9125, Training F1: 0.9120, Validation Loss: 0.2762, Validation Accuracy: 0.8978, Validation F1: 0.8993\n",
      "Epoch 18/25, Training Loss: 0.2315, Training Accuracy: 0.9131, Training F1: 0.9127, Validation Loss: 0.2854, Validation Accuracy: 0.8928, Validation F1: 0.8952\n",
      "Epoch 19/25, Training Loss: 0.2241, Training Accuracy: 0.9168, Training F1: 0.9164, Validation Loss: 0.2695, Validation Accuracy: 0.9043, Validation F1: 0.9044\n",
      "Epoch 20/25, Training Loss: 0.2187, Training Accuracy: 0.9190, Training F1: 0.9185, Validation Loss: 0.2778, Validation Accuracy: 0.8973, Validation F1: 0.8987\n",
      "Epoch 21/25, Training Loss: 0.2185, Training Accuracy: 0.9192, Training F1: 0.9188, Validation Loss: 0.2648, Validation Accuracy: 0.9003, Validation F1: 0.9023\n",
      "Epoch 22/25, Training Loss: 0.2148, Training Accuracy: 0.9195, Training F1: 0.9191, Validation Loss: 0.2768, Validation Accuracy: 0.9000, Validation F1: 0.9026\n",
      "Epoch 23/25, Training Loss: 0.2069, Training Accuracy: 0.9218, Training F1: 0.9214, Validation Loss: 0.2752, Validation Accuracy: 0.8910, Validation F1: 0.8933\n",
      "Epoch 24/25, Training Loss: 0.1997, Training Accuracy: 0.9260, Training F1: 0.9256, Validation Loss: 0.2809, Validation Accuracy: 0.8992, Validation F1: 0.9001\n",
      "Epoch 25/25, Training Loss: 0.1957, Training Accuracy: 0.9269, Training F1: 0.9265, Validation Loss: 0.2770, Validation Accuracy: 0.9015, Validation F1: 0.9033\n",
      "Test Loss: 0.2760, Test Accuracy: 0.9037, Test F1 Score: 0.9039\n",
      "\n",
      "Training models for architecture: Arch2\n",
      "  Training with learning rate: 0.005\n",
      "Epoch 1/25, Training Loss: 0.5739, Training Accuracy: 0.7968, Training F1: 0.7945, Validation Loss: 0.3818, Validation Accuracy: 0.8560, Validation F1: 0.8569\n",
      "Epoch 2/25, Training Loss: 0.4481, Training Accuracy: 0.8419, Training F1: 0.8406, Validation Loss: 0.3452, Validation Accuracy: 0.8725, Validation F1: 0.8719\n",
      "Epoch 3/25, Training Loss: 0.4084, Training Accuracy: 0.8561, Training F1: 0.8550, Validation Loss: 0.3305, Validation Accuracy: 0.8813, Validation F1: 0.8805\n",
      "Epoch 4/25, Training Loss: 0.3815, Training Accuracy: 0.8646, Training F1: 0.8637, Validation Loss: 0.3198, Validation Accuracy: 0.8813, Validation F1: 0.8826\n",
      "Epoch 5/25, Training Loss: 0.3606, Training Accuracy: 0.8696, Training F1: 0.8688, Validation Loss: 0.3069, Validation Accuracy: 0.8832, Validation F1: 0.8853\n",
      "Epoch 6/25, Training Loss: 0.3483, Training Accuracy: 0.8748, Training F1: 0.8740, Validation Loss: 0.3015, Validation Accuracy: 0.8828, Validation F1: 0.8838\n",
      "Epoch 7/25, Training Loss: 0.3319, Training Accuracy: 0.8799, Training F1: 0.8791, Validation Loss: 0.3219, Validation Accuracy: 0.8793, Validation F1: 0.8809\n",
      "Epoch 8/25, Training Loss: 0.3166, Training Accuracy: 0.8848, Training F1: 0.8840, Validation Loss: 0.2925, Validation Accuracy: 0.8898, Validation F1: 0.8897\n",
      "Epoch 9/25, Training Loss: 0.3085, Training Accuracy: 0.8890, Training F1: 0.8883, Validation Loss: 0.2979, Validation Accuracy: 0.8868, Validation F1: 0.8879\n",
      "Epoch 10/25, Training Loss: 0.2971, Training Accuracy: 0.8922, Training F1: 0.8915, Validation Loss: 0.2781, Validation Accuracy: 0.9002, Validation F1: 0.9004\n",
      "Epoch 11/25, Training Loss: 0.2881, Training Accuracy: 0.8955, Training F1: 0.8949, Validation Loss: 0.2828, Validation Accuracy: 0.8942, Validation F1: 0.8960\n",
      "Epoch 12/25, Training Loss: 0.2765, Training Accuracy: 0.8992, Training F1: 0.8986, Validation Loss: 0.3009, Validation Accuracy: 0.8918, Validation F1: 0.8931\n",
      "Epoch 13/25, Training Loss: 0.2716, Training Accuracy: 0.9012, Training F1: 0.9006, Validation Loss: 0.2934, Validation Accuracy: 0.8907, Validation F1: 0.8901\n",
      "Epoch 14/25, Training Loss: 0.2613, Training Accuracy: 0.9036, Training F1: 0.9031, Validation Loss: 0.2700, Validation Accuracy: 0.8995, Validation F1: 0.9007\n",
      "Epoch 15/25, Training Loss: 0.2529, Training Accuracy: 0.9077, Training F1: 0.9072, Validation Loss: 0.2788, Validation Accuracy: 0.8975, Validation F1: 0.8992\n",
      "Epoch 16/25, Training Loss: 0.2461, Training Accuracy: 0.9114, Training F1: 0.9109, Validation Loss: 0.2796, Validation Accuracy: 0.8915, Validation F1: 0.8924\n",
      "Epoch 17/25, Training Loss: 0.2408, Training Accuracy: 0.9104, Training F1: 0.9099, Validation Loss: 0.2789, Validation Accuracy: 0.8955, Validation F1: 0.8968\n",
      "Epoch 18/25, Training Loss: 0.2311, Training Accuracy: 0.9152, Training F1: 0.9148, Validation Loss: 0.2999, Validation Accuracy: 0.8947, Validation F1: 0.8942\n",
      "Epoch 19/25, Training Loss: 0.2275, Training Accuracy: 0.9150, Training F1: 0.9145, Validation Loss: 0.2738, Validation Accuracy: 0.9022, Validation F1: 0.9036\n",
      "Epoch 20/25, Training Loss: 0.2197, Training Accuracy: 0.9196, Training F1: 0.9192, Validation Loss: 0.2711, Validation Accuracy: 0.9037, Validation F1: 0.9044\n",
      "Epoch 21/25, Training Loss: 0.2145, Training Accuracy: 0.9216, Training F1: 0.9212, Validation Loss: 0.2788, Validation Accuracy: 0.8977, Validation F1: 0.8995\n",
      "Epoch 22/25, Training Loss: 0.2085, Training Accuracy: 0.9237, Training F1: 0.9233, Validation Loss: 0.2742, Validation Accuracy: 0.9088, Validation F1: 0.9101\n",
      "Epoch 23/25, Training Loss: 0.2089, Training Accuracy: 0.9234, Training F1: 0.9231, Validation Loss: 0.2721, Validation Accuracy: 0.9028, Validation F1: 0.9034\n",
      "Epoch 24/25, Training Loss: 0.2020, Training Accuracy: 0.9257, Training F1: 0.9253, Validation Loss: 0.2681, Validation Accuracy: 0.9053, Validation F1: 0.9068\n",
      "Epoch 25/25, Training Loss: 0.1970, Training Accuracy: 0.9280, Training F1: 0.9276, Validation Loss: 0.2960, Validation Accuracy: 0.8963, Validation F1: 0.8995\n",
      "Test Loss: 0.2919, Test Accuracy: 0.8974, Test F1 Score: 0.8985\n",
      "  Training with learning rate: 0.001\n",
      "Epoch 1/25, Training Loss: 0.5955, Training Accuracy: 0.7941, Training F1: 0.7917, Validation Loss: 0.3628, Validation Accuracy: 0.8662, Validation F1: 0.8653\n",
      "Epoch 2/25, Training Loss: 0.4321, Training Accuracy: 0.8456, Training F1: 0.8443, Validation Loss: 0.3320, Validation Accuracy: 0.8783, Validation F1: 0.8802\n",
      "Epoch 3/25, Training Loss: 0.3922, Training Accuracy: 0.8595, Training F1: 0.8586, Validation Loss: 0.3180, Validation Accuracy: 0.8850, Validation F1: 0.8864\n",
      "Epoch 4/25, Training Loss: 0.3702, Training Accuracy: 0.8671, Training F1: 0.8662, Validation Loss: 0.3232, Validation Accuracy: 0.8793, Validation F1: 0.8800\n",
      "Epoch 5/25, Training Loss: 0.3474, Training Accuracy: 0.8735, Training F1: 0.8728, Validation Loss: 0.2969, Validation Accuracy: 0.8887, Validation F1: 0.8909\n",
      "Epoch 6/25, Training Loss: 0.3301, Training Accuracy: 0.8806, Training F1: 0.8800, Validation Loss: 0.2984, Validation Accuracy: 0.8898, Validation F1: 0.8907\n",
      "Epoch 7/25, Training Loss: 0.3179, Training Accuracy: 0.8842, Training F1: 0.8836, Validation Loss: 0.2895, Validation Accuracy: 0.8925, Validation F1: 0.8939\n",
      "Epoch 8/25, Training Loss: 0.3073, Training Accuracy: 0.8886, Training F1: 0.8880, Validation Loss: 0.2991, Validation Accuracy: 0.8857, Validation F1: 0.8880\n",
      "Epoch 9/25, Training Loss: 0.2946, Training Accuracy: 0.8928, Training F1: 0.8922, Validation Loss: 0.3001, Validation Accuracy: 0.8895, Validation F1: 0.8896\n",
      "Epoch 10/25, Training Loss: 0.2867, Training Accuracy: 0.8958, Training F1: 0.8952, Validation Loss: 0.2971, Validation Accuracy: 0.8908, Validation F1: 0.8917\n",
      "Epoch 11/25, Training Loss: 0.2749, Training Accuracy: 0.9017, Training F1: 0.9012, Validation Loss: 0.3315, Validation Accuracy: 0.8757, Validation F1: 0.8812\n",
      "Epoch 12/25, Training Loss: 0.2660, Training Accuracy: 0.9023, Training F1: 0.9017, Validation Loss: 0.2732, Validation Accuracy: 0.8993, Validation F1: 0.9010\n",
      "Epoch 13/25, Training Loss: 0.2604, Training Accuracy: 0.9044, Training F1: 0.9039, Validation Loss: 0.2902, Validation Accuracy: 0.8943, Validation F1: 0.8953\n",
      "Epoch 14/25, Training Loss: 0.2481, Training Accuracy: 0.9077, Training F1: 0.9072, Validation Loss: 0.2735, Validation Accuracy: 0.9040, Validation F1: 0.9051\n",
      "Epoch 15/25, Training Loss: 0.2411, Training Accuracy: 0.9113, Training F1: 0.9108, Validation Loss: 0.2909, Validation Accuracy: 0.8925, Validation F1: 0.8912\n",
      "Epoch 16/25, Training Loss: 0.2363, Training Accuracy: 0.9141, Training F1: 0.9137, Validation Loss: 0.2704, Validation Accuracy: 0.9003, Validation F1: 0.9017\n",
      "Epoch 17/25, Training Loss: 0.2295, Training Accuracy: 0.9155, Training F1: 0.9151, Validation Loss: 0.2901, Validation Accuracy: 0.8987, Validation F1: 0.8989\n",
      "Epoch 18/25, Training Loss: 0.2227, Training Accuracy: 0.9186, Training F1: 0.9182, Validation Loss: 0.2803, Validation Accuracy: 0.8977, Validation F1: 0.8992\n",
      "Epoch 19/25, Training Loss: 0.2179, Training Accuracy: 0.9190, Training F1: 0.9185, Validation Loss: 0.2934, Validation Accuracy: 0.8980, Validation F1: 0.8974\n",
      "Epoch 20/25, Training Loss: 0.2064, Training Accuracy: 0.9239, Training F1: 0.9236, Validation Loss: 0.2707, Validation Accuracy: 0.9037, Validation F1: 0.9050\n",
      "Epoch 21/25, Training Loss: 0.2037, Training Accuracy: 0.9246, Training F1: 0.9241, Validation Loss: 0.2872, Validation Accuracy: 0.9032, Validation F1: 0.9027\n",
      "Epoch 22/25, Training Loss: 0.2003, Training Accuracy: 0.9266, Training F1: 0.9263, Validation Loss: 0.2782, Validation Accuracy: 0.9023, Validation F1: 0.9021\n",
      "Epoch 23/25, Training Loss: 0.1927, Training Accuracy: 0.9294, Training F1: 0.9291, Validation Loss: 0.2746, Validation Accuracy: 0.9047, Validation F1: 0.9058\n",
      "Epoch 24/25, Training Loss: 0.1875, Training Accuracy: 0.9303, Training F1: 0.9300, Validation Loss: 0.2739, Validation Accuracy: 0.9032, Validation F1: 0.9045\n",
      "Epoch 25/25, Training Loss: 0.1845, Training Accuracy: 0.9318, Training F1: 0.9315, Validation Loss: 0.2811, Validation Accuracy: 0.9063, Validation F1: 0.9070\n",
      "Test Loss: 0.2755, Test Accuracy: 0.9047, Test F1 Score: 0.9033\n",
      "  Training with learning rate: 0.0009\n",
      "Epoch 1/25, Training Loss: 0.5995, Training Accuracy: 0.7938, Training F1: 0.7918, Validation Loss: 0.3649, Validation Accuracy: 0.8680, Validation F1: 0.8700\n",
      "Epoch 2/25, Training Loss: 0.4348, Training Accuracy: 0.8456, Training F1: 0.8446, Validation Loss: 0.3325, Validation Accuracy: 0.8823, Validation F1: 0.8823\n",
      "Epoch 3/25, Training Loss: 0.3949, Training Accuracy: 0.8585, Training F1: 0.8575, Validation Loss: 0.3286, Validation Accuracy: 0.8777, Validation F1: 0.8781\n",
      "Epoch 4/25, Training Loss: 0.3677, Training Accuracy: 0.8686, Training F1: 0.8675, Validation Loss: 0.3170, Validation Accuracy: 0.8817, Validation F1: 0.8819\n",
      "Epoch 5/25, Training Loss: 0.3484, Training Accuracy: 0.8743, Training F1: 0.8734, Validation Loss: 0.3148, Validation Accuracy: 0.8810, Validation F1: 0.8811\n",
      "Epoch 6/25, Training Loss: 0.3329, Training Accuracy: 0.8801, Training F1: 0.8794, Validation Loss: 0.3056, Validation Accuracy: 0.8852, Validation F1: 0.8864\n",
      "Epoch 7/25, Training Loss: 0.3153, Training Accuracy: 0.8863, Training F1: 0.8856, Validation Loss: 0.3102, Validation Accuracy: 0.8822, Validation F1: 0.8778\n",
      "Epoch 8/25, Training Loss: 0.3060, Training Accuracy: 0.8882, Training F1: 0.8874, Validation Loss: 0.3007, Validation Accuracy: 0.8875, Validation F1: 0.8870\n",
      "Epoch 9/25, Training Loss: 0.2939, Training Accuracy: 0.8933, Training F1: 0.8926, Validation Loss: 0.2907, Validation Accuracy: 0.8945, Validation F1: 0.8952\n",
      "Epoch 10/25, Training Loss: 0.2858, Training Accuracy: 0.8957, Training F1: 0.8951, Validation Loss: 0.2844, Validation Accuracy: 0.8925, Validation F1: 0.8925\n",
      "Epoch 11/25, Training Loss: 0.2753, Training Accuracy: 0.9001, Training F1: 0.8995, Validation Loss: 0.2847, Validation Accuracy: 0.8915, Validation F1: 0.8937\n",
      "Epoch 12/25, Training Loss: 0.2667, Training Accuracy: 0.9024, Training F1: 0.9018, Validation Loss: 0.3204, Validation Accuracy: 0.8853, Validation F1: 0.8818\n",
      "Epoch 13/25, Training Loss: 0.2568, Training Accuracy: 0.9061, Training F1: 0.9056, Validation Loss: 0.2724, Validation Accuracy: 0.8958, Validation F1: 0.8980\n",
      "Epoch 14/25, Training Loss: 0.2497, Training Accuracy: 0.9086, Training F1: 0.9081, Validation Loss: 0.2701, Validation Accuracy: 0.8962, Validation F1: 0.8969\n",
      "Epoch 15/25, Training Loss: 0.2424, Training Accuracy: 0.9114, Training F1: 0.9109, Validation Loss: 0.2833, Validation Accuracy: 0.8967, Validation F1: 0.8967\n",
      "Epoch 16/25, Training Loss: 0.2338, Training Accuracy: 0.9134, Training F1: 0.9129, Validation Loss: 0.2691, Validation Accuracy: 0.9008, Validation F1: 0.9030\n",
      "Epoch 17/25, Training Loss: 0.2259, Training Accuracy: 0.9161, Training F1: 0.9157, Validation Loss: 0.2783, Validation Accuracy: 0.8980, Validation F1: 0.9008\n",
      "Epoch 18/25, Training Loss: 0.2222, Training Accuracy: 0.9181, Training F1: 0.9176, Validation Loss: 0.2756, Validation Accuracy: 0.9012, Validation F1: 0.9021\n",
      "Epoch 19/25, Training Loss: 0.2159, Training Accuracy: 0.9209, Training F1: 0.9205, Validation Loss: 0.2873, Validation Accuracy: 0.8942, Validation F1: 0.8962\n",
      "Epoch 20/25, Training Loss: 0.2124, Training Accuracy: 0.9216, Training F1: 0.9212, Validation Loss: 0.2670, Validation Accuracy: 0.9070, Validation F1: 0.9085\n",
      "Epoch 21/25, Training Loss: 0.2030, Training Accuracy: 0.9259, Training F1: 0.9256, Validation Loss: 0.2783, Validation Accuracy: 0.9010, Validation F1: 0.9022\n",
      "Epoch 22/25, Training Loss: 0.1974, Training Accuracy: 0.9264, Training F1: 0.9259, Validation Loss: 0.2996, Validation Accuracy: 0.8997, Validation F1: 0.8992\n",
      "Epoch 23/25, Training Loss: 0.1953, Training Accuracy: 0.9284, Training F1: 0.9280, Validation Loss: 0.2735, Validation Accuracy: 0.9060, Validation F1: 0.9074\n",
      "Epoch 24/25, Training Loss: 0.1885, Training Accuracy: 0.9303, Training F1: 0.9299, Validation Loss: 0.2777, Validation Accuracy: 0.9077, Validation F1: 0.9085\n",
      "Epoch 25/25, Training Loss: 0.1834, Training Accuracy: 0.9325, Training F1: 0.9322, Validation Loss: 0.2922, Validation Accuracy: 0.8990, Validation F1: 0.9014\n",
      "Test Loss: 0.2898, Test Accuracy: 0.8986, Test F1 Score: 0.8989\n",
      "  Training with learning rate: 0.0006\n",
      "Epoch 1/25, Training Loss: 0.6249, Training Accuracy: 0.7866, Training F1: 0.7849, Validation Loss: 0.3676, Validation Accuracy: 0.8658, Validation F1: 0.8642\n",
      "Epoch 2/25, Training Loss: 0.4413, Training Accuracy: 0.8439, Training F1: 0.8428, Validation Loss: 0.3355, Validation Accuracy: 0.8718, Validation F1: 0.8715\n",
      "Epoch 3/25, Training Loss: 0.3999, Training Accuracy: 0.8581, Training F1: 0.8572, Validation Loss: 0.3099, Validation Accuracy: 0.8860, Validation F1: 0.8856\n",
      "Epoch 4/25, Training Loss: 0.3712, Training Accuracy: 0.8661, Training F1: 0.8653, Validation Loss: 0.3146, Validation Accuracy: 0.8837, Validation F1: 0.8828\n",
      "Epoch 5/25, Training Loss: 0.3462, Training Accuracy: 0.8761, Training F1: 0.8753, Validation Loss: 0.3065, Validation Accuracy: 0.8882, Validation F1: 0.8880\n",
      "Epoch 6/25, Training Loss: 0.3329, Training Accuracy: 0.8793, Training F1: 0.8785, Validation Loss: 0.3258, Validation Accuracy: 0.8777, Validation F1: 0.8802\n",
      "Epoch 7/25, Training Loss: 0.3183, Training Accuracy: 0.8835, Training F1: 0.8828, Validation Loss: 0.2945, Validation Accuracy: 0.8903, Validation F1: 0.8907\n",
      "Epoch 8/25, Training Loss: 0.3051, Training Accuracy: 0.8886, Training F1: 0.8880, Validation Loss: 0.3050, Validation Accuracy: 0.8877, Validation F1: 0.8893\n",
      "Epoch 9/25, Training Loss: 0.2971, Training Accuracy: 0.8925, Training F1: 0.8918, Validation Loss: 0.3047, Validation Accuracy: 0.8865, Validation F1: 0.8861\n",
      "Epoch 10/25, Training Loss: 0.2847, Training Accuracy: 0.8946, Training F1: 0.8940, Validation Loss: 0.2738, Validation Accuracy: 0.9013, Validation F1: 0.9021\n",
      "Epoch 11/25, Training Loss: 0.2767, Training Accuracy: 0.8988, Training F1: 0.8983, Validation Loss: 0.2878, Validation Accuracy: 0.8928, Validation F1: 0.8937\n",
      "Epoch 12/25, Training Loss: 0.2664, Training Accuracy: 0.9025, Training F1: 0.9019, Validation Loss: 0.2649, Validation Accuracy: 0.9020, Validation F1: 0.9035\n",
      "Epoch 13/25, Training Loss: 0.2565, Training Accuracy: 0.9055, Training F1: 0.9050, Validation Loss: 0.2983, Validation Accuracy: 0.8912, Validation F1: 0.8903\n",
      "Epoch 14/25, Training Loss: 0.2505, Training Accuracy: 0.9077, Training F1: 0.9071, Validation Loss: 0.2793, Validation Accuracy: 0.8977, Validation F1: 0.8979\n",
      "Epoch 15/25, Training Loss: 0.2398, Training Accuracy: 0.9116, Training F1: 0.9112, Validation Loss: 0.2903, Validation Accuracy: 0.8963, Validation F1: 0.8956\n",
      "Epoch 16/25, Training Loss: 0.2339, Training Accuracy: 0.9140, Training F1: 0.9135, Validation Loss: 0.2606, Validation Accuracy: 0.9000, Validation F1: 0.9014\n",
      "Epoch 17/25, Training Loss: 0.2293, Training Accuracy: 0.9163, Training F1: 0.9159, Validation Loss: 0.2600, Validation Accuracy: 0.9052, Validation F1: 0.9060\n",
      "Epoch 18/25, Training Loss: 0.2225, Training Accuracy: 0.9185, Training F1: 0.9180, Validation Loss: 0.2836, Validation Accuracy: 0.8992, Validation F1: 0.8996\n",
      "Epoch 19/25, Training Loss: 0.2177, Training Accuracy: 0.9206, Training F1: 0.9202, Validation Loss: 0.2653, Validation Accuracy: 0.9032, Validation F1: 0.9049\n",
      "Epoch 20/25, Training Loss: 0.2074, Training Accuracy: 0.9231, Training F1: 0.9227, Validation Loss: 0.2671, Validation Accuracy: 0.9065, Validation F1: 0.9076\n",
      "Epoch 21/25, Training Loss: 0.2085, Training Accuracy: 0.9233, Training F1: 0.9229, Validation Loss: 0.2589, Validation Accuracy: 0.9093, Validation F1: 0.9103\n",
      "Epoch 22/25, Training Loss: 0.2018, Training Accuracy: 0.9256, Training F1: 0.9252, Validation Loss: 0.2756, Validation Accuracy: 0.9047, Validation F1: 0.9058\n",
      "Epoch 23/25, Training Loss: 0.1940, Training Accuracy: 0.9289, Training F1: 0.9285, Validation Loss: 0.2681, Validation Accuracy: 0.9000, Validation F1: 0.9011\n",
      "Epoch 24/25, Training Loss: 0.1894, Training Accuracy: 0.9301, Training F1: 0.9297, Validation Loss: 0.2908, Validation Accuracy: 0.8923, Validation F1: 0.8955\n",
      "Epoch 25/25, Training Loss: 0.1845, Training Accuracy: 0.9321, Training F1: 0.9318, Validation Loss: 0.3115, Validation Accuracy: 0.8977, Validation F1: 0.8969\n",
      "Test Loss: 0.2981, Test Accuracy: 0.8986, Test F1 Score: 0.8967\n",
      "\n",
      "Training models for architecture: Arch3\n",
      "  Training with learning rate: 0.005\n",
      "Epoch 1/25, Training Loss: 0.5420, Training Accuracy: 0.8067, Training F1: 0.8053, Validation Loss: 0.3835, Validation Accuracy: 0.8565, Validation F1: 0.8578\n",
      "Epoch 2/25, Training Loss: 0.4264, Training Accuracy: 0.8454, Training F1: 0.8444, Validation Loss: 0.3732, Validation Accuracy: 0.8597, Validation F1: 0.8582\n",
      "Epoch 3/25, Training Loss: 0.3912, Training Accuracy: 0.8583, Training F1: 0.8573, Validation Loss: 0.3348, Validation Accuracy: 0.8777, Validation F1: 0.8764\n",
      "Epoch 4/25, Training Loss: 0.3700, Training Accuracy: 0.8653, Training F1: 0.8644, Validation Loss: 0.3667, Validation Accuracy: 0.8647, Validation F1: 0.8644\n",
      "Epoch 5/25, Training Loss: 0.3507, Training Accuracy: 0.8710, Training F1: 0.8703, Validation Loss: 0.3102, Validation Accuracy: 0.8833, Validation F1: 0.8850\n",
      "Epoch 6/25, Training Loss: 0.3335, Training Accuracy: 0.8767, Training F1: 0.8760, Validation Loss: 0.3014, Validation Accuracy: 0.8890, Validation F1: 0.8893\n",
      "Epoch 7/25, Training Loss: 0.3256, Training Accuracy: 0.8799, Training F1: 0.8791, Validation Loss: 0.2990, Validation Accuracy: 0.8880, Validation F1: 0.8893\n",
      "Epoch 8/25, Training Loss: 0.3181, Training Accuracy: 0.8827, Training F1: 0.8819, Validation Loss: 0.2905, Validation Accuracy: 0.8978, Validation F1: 0.8984\n",
      "Epoch 9/25, Training Loss: 0.3051, Training Accuracy: 0.8878, Training F1: 0.8871, Validation Loss: 0.2993, Validation Accuracy: 0.8890, Validation F1: 0.8905\n",
      "Epoch 10/25, Training Loss: 0.2998, Training Accuracy: 0.8895, Training F1: 0.8888, Validation Loss: 0.2846, Validation Accuracy: 0.8948, Validation F1: 0.8947\n",
      "Epoch 11/25, Training Loss: 0.2915, Training Accuracy: 0.8919, Training F1: 0.8912, Validation Loss: 0.2823, Validation Accuracy: 0.8942, Validation F1: 0.8950\n",
      "Epoch 12/25, Training Loss: 0.2829, Training Accuracy: 0.8955, Training F1: 0.8950, Validation Loss: 0.2978, Validation Accuracy: 0.8883, Validation F1: 0.8889\n",
      "Epoch 13/25, Training Loss: 0.2778, Training Accuracy: 0.8972, Training F1: 0.8966, Validation Loss: 0.2802, Validation Accuracy: 0.8948, Validation F1: 0.8968\n",
      "Epoch 14/25, Training Loss: 0.2677, Training Accuracy: 0.9009, Training F1: 0.9003, Validation Loss: 0.3030, Validation Accuracy: 0.8905, Validation F1: 0.8898\n",
      "Epoch 15/25, Training Loss: 0.2632, Training Accuracy: 0.9014, Training F1: 0.9009, Validation Loss: 0.2830, Validation Accuracy: 0.8958, Validation F1: 0.8968\n",
      "Epoch 16/25, Training Loss: 0.2599, Training Accuracy: 0.9030, Training F1: 0.9025, Validation Loss: 0.2796, Validation Accuracy: 0.9035, Validation F1: 0.9042\n",
      "Epoch 17/25, Training Loss: 0.2541, Training Accuracy: 0.9047, Training F1: 0.9041, Validation Loss: 0.2861, Validation Accuracy: 0.8958, Validation F1: 0.8973\n",
      "Epoch 18/25, Training Loss: 0.2470, Training Accuracy: 0.9072, Training F1: 0.9067, Validation Loss: 0.2853, Validation Accuracy: 0.8998, Validation F1: 0.9004\n",
      "Epoch 19/25, Training Loss: 0.2483, Training Accuracy: 0.9059, Training F1: 0.9053, Validation Loss: 0.2779, Validation Accuracy: 0.9018, Validation F1: 0.9025\n",
      "Epoch 20/25, Training Loss: 0.2398, Training Accuracy: 0.9105, Training F1: 0.9100, Validation Loss: 0.2833, Validation Accuracy: 0.8985, Validation F1: 0.8998\n",
      "Epoch 21/25, Training Loss: 0.2372, Training Accuracy: 0.9111, Training F1: 0.9106, Validation Loss: 0.2829, Validation Accuracy: 0.9015, Validation F1: 0.9035\n",
      "Epoch 22/25, Training Loss: 0.2344, Training Accuracy: 0.9124, Training F1: 0.9119, Validation Loss: 0.2875, Validation Accuracy: 0.8975, Validation F1: 0.8978\n",
      "Epoch 23/25, Training Loss: 0.2302, Training Accuracy: 0.9143, Training F1: 0.9138, Validation Loss: 0.2847, Validation Accuracy: 0.8990, Validation F1: 0.9008\n",
      "Epoch 24/25, Training Loss: 0.2285, Training Accuracy: 0.9145, Training F1: 0.9140, Validation Loss: 0.2835, Validation Accuracy: 0.9028, Validation F1: 0.9040\n",
      "Epoch 25/25, Training Loss: 0.2225, Training Accuracy: 0.9167, Training F1: 0.9162, Validation Loss: 0.2780, Validation Accuracy: 0.9025, Validation F1: 0.9037\n",
      "Test Loss: 0.2782, Test Accuracy: 0.9030, Test F1 Score: 0.9026\n",
      "  Training with learning rate: 0.001\n",
      "Epoch 1/25, Training Loss: 0.5711, Training Accuracy: 0.7985, Training F1: 0.7967, Validation Loss: 0.3716, Validation Accuracy: 0.8632, Validation F1: 0.8640\n",
      "Epoch 2/25, Training Loss: 0.4306, Training Accuracy: 0.8447, Training F1: 0.8437, Validation Loss: 0.3425, Validation Accuracy: 0.8695, Validation F1: 0.8722\n",
      "Epoch 3/25, Training Loss: 0.3873, Training Accuracy: 0.8601, Training F1: 0.8593, Validation Loss: 0.3196, Validation Accuracy: 0.8812, Validation F1: 0.8825\n",
      "Epoch 4/25, Training Loss: 0.3634, Training Accuracy: 0.8680, Training F1: 0.8672, Validation Loss: 0.3310, Validation Accuracy: 0.8790, Validation F1: 0.8786\n",
      "Epoch 5/25, Training Loss: 0.3476, Training Accuracy: 0.8736, Training F1: 0.8728, Validation Loss: 0.3094, Validation Accuracy: 0.8832, Validation F1: 0.8852\n",
      "Epoch 6/25, Training Loss: 0.3330, Training Accuracy: 0.8772, Training F1: 0.8765, Validation Loss: 0.2989, Validation Accuracy: 0.8848, Validation F1: 0.8856\n",
      "Epoch 7/25, Training Loss: 0.3176, Training Accuracy: 0.8844, Training F1: 0.8837, Validation Loss: 0.2870, Validation Accuracy: 0.8927, Validation F1: 0.8936\n",
      "Epoch 8/25, Training Loss: 0.3118, Training Accuracy: 0.8845, Training F1: 0.8838, Validation Loss: 0.2959, Validation Accuracy: 0.8917, Validation F1: 0.8919\n",
      "Epoch 9/25, Training Loss: 0.2986, Training Accuracy: 0.8903, Training F1: 0.8897, Validation Loss: 0.2856, Validation Accuracy: 0.8900, Validation F1: 0.8920\n",
      "Epoch 10/25, Training Loss: 0.2863, Training Accuracy: 0.8946, Training F1: 0.8941, Validation Loss: 0.2815, Validation Accuracy: 0.8963, Validation F1: 0.8967\n",
      "Epoch 11/25, Training Loss: 0.2797, Training Accuracy: 0.8981, Training F1: 0.8975, Validation Loss: 0.2804, Validation Accuracy: 0.8965, Validation F1: 0.8976\n",
      "Epoch 12/25, Training Loss: 0.2721, Training Accuracy: 0.8997, Training F1: 0.8991, Validation Loss: 0.2901, Validation Accuracy: 0.8962, Validation F1: 0.8961\n",
      "Epoch 13/25, Training Loss: 0.2674, Training Accuracy: 0.9006, Training F1: 0.9001, Validation Loss: 0.2770, Validation Accuracy: 0.8988, Validation F1: 0.8997\n",
      "Epoch 14/25, Training Loss: 0.2611, Training Accuracy: 0.9042, Training F1: 0.9037, Validation Loss: 0.2832, Validation Accuracy: 0.8950, Validation F1: 0.8965\n",
      "Epoch 15/25, Training Loss: 0.2559, Training Accuracy: 0.9053, Training F1: 0.9049, Validation Loss: 0.2770, Validation Accuracy: 0.8982, Validation F1: 0.8994\n",
      "Epoch 16/25, Training Loss: 0.2490, Training Accuracy: 0.9076, Training F1: 0.9071, Validation Loss: 0.2699, Validation Accuracy: 0.9005, Validation F1: 0.9024\n",
      "Epoch 17/25, Training Loss: 0.2399, Training Accuracy: 0.9101, Training F1: 0.9096, Validation Loss: 0.2710, Validation Accuracy: 0.9037, Validation F1: 0.9044\n",
      "Epoch 18/25, Training Loss: 0.2371, Training Accuracy: 0.9126, Training F1: 0.9121, Validation Loss: 0.2767, Validation Accuracy: 0.9023, Validation F1: 0.9038\n",
      "Epoch 19/25, Training Loss: 0.2319, Training Accuracy: 0.9139, Training F1: 0.9135, Validation Loss: 0.2734, Validation Accuracy: 0.9022, Validation F1: 0.9031\n",
      "Epoch 20/25, Training Loss: 0.2291, Training Accuracy: 0.9140, Training F1: 0.9136, Validation Loss: 0.2726, Validation Accuracy: 0.9030, Validation F1: 0.9037\n",
      "Epoch 21/25, Training Loss: 0.2256, Training Accuracy: 0.9158, Training F1: 0.9153, Validation Loss: 0.2746, Validation Accuracy: 0.9027, Validation F1: 0.9033\n",
      "Epoch 22/25, Training Loss: 0.2215, Training Accuracy: 0.9170, Training F1: 0.9166, Validation Loss: 0.2833, Validation Accuracy: 0.9027, Validation F1: 0.9028\n",
      "Epoch 23/25, Training Loss: 0.2159, Training Accuracy: 0.9190, Training F1: 0.9186, Validation Loss: 0.2785, Validation Accuracy: 0.9020, Validation F1: 0.9036\n",
      "Epoch 24/25, Training Loss: 0.2158, Training Accuracy: 0.9197, Training F1: 0.9193, Validation Loss: 0.2829, Validation Accuracy: 0.9015, Validation F1: 0.9025\n",
      "Epoch 25/25, Training Loss: 0.2103, Training Accuracy: 0.9215, Training F1: 0.9212, Validation Loss: 0.2683, Validation Accuracy: 0.9048, Validation F1: 0.9062\n",
      "Test Loss: 0.2727, Test Accuracy: 0.9041, Test F1 Score: 0.9039\n",
      "  Training with learning rate: 0.0009\n",
      "Epoch 1/25, Training Loss: 0.5748, Training Accuracy: 0.7978, Training F1: 0.7963, Validation Loss: 0.3892, Validation Accuracy: 0.8563, Validation F1: 0.8553\n",
      "Epoch 2/25, Training Loss: 0.4306, Training Accuracy: 0.8437, Training F1: 0.8426, Validation Loss: 0.3393, Validation Accuracy: 0.8757, Validation F1: 0.8755\n",
      "Epoch 3/25, Training Loss: 0.3917, Training Accuracy: 0.8587, Training F1: 0.8578, Validation Loss: 0.3366, Validation Accuracy: 0.8725, Validation F1: 0.8731\n",
      "Epoch 4/25, Training Loss: 0.3673, Training Accuracy: 0.8672, Training F1: 0.8665, Validation Loss: 0.3282, Validation Accuracy: 0.8758, Validation F1: 0.8735\n",
      "Epoch 5/25, Training Loss: 0.3456, Training Accuracy: 0.8740, Training F1: 0.8734, Validation Loss: 0.3073, Validation Accuracy: 0.8848, Validation F1: 0.8864\n",
      "Epoch 6/25, Training Loss: 0.3343, Training Accuracy: 0.8766, Training F1: 0.8759, Validation Loss: 0.3020, Validation Accuracy: 0.8853, Validation F1: 0.8842\n",
      "Epoch 7/25, Training Loss: 0.3212, Training Accuracy: 0.8828, Training F1: 0.8821, Validation Loss: 0.3022, Validation Accuracy: 0.8870, Validation F1: 0.8862\n",
      "Epoch 8/25, Training Loss: 0.3064, Training Accuracy: 0.8880, Training F1: 0.8874, Validation Loss: 0.2955, Validation Accuracy: 0.8897, Validation F1: 0.8908\n",
      "Epoch 9/25, Training Loss: 0.2998, Training Accuracy: 0.8897, Training F1: 0.8891, Validation Loss: 0.2884, Validation Accuracy: 0.8923, Validation F1: 0.8920\n",
      "Epoch 10/25, Training Loss: 0.2901, Training Accuracy: 0.8925, Training F1: 0.8919, Validation Loss: 0.2785, Validation Accuracy: 0.8987, Validation F1: 0.9003\n",
      "Epoch 11/25, Training Loss: 0.2817, Training Accuracy: 0.8944, Training F1: 0.8938, Validation Loss: 0.2825, Validation Accuracy: 0.8960, Validation F1: 0.8969\n",
      "Epoch 12/25, Training Loss: 0.2737, Training Accuracy: 0.8979, Training F1: 0.8974, Validation Loss: 0.2661, Validation Accuracy: 0.9000, Validation F1: 0.9004\n",
      "Epoch 13/25, Training Loss: 0.2685, Training Accuracy: 0.9014, Training F1: 0.9009, Validation Loss: 0.2799, Validation Accuracy: 0.8977, Validation F1: 0.8988\n",
      "Epoch 14/25, Training Loss: 0.2608, Training Accuracy: 0.9031, Training F1: 0.9025, Validation Loss: 0.2705, Validation Accuracy: 0.8987, Validation F1: 0.9003\n",
      "Epoch 15/25, Training Loss: 0.2529, Training Accuracy: 0.9051, Training F1: 0.9046, Validation Loss: 0.2805, Validation Accuracy: 0.8922, Validation F1: 0.8948\n",
      "Epoch 16/25, Training Loss: 0.2494, Training Accuracy: 0.9078, Training F1: 0.9073, Validation Loss: 0.2695, Validation Accuracy: 0.8980, Validation F1: 0.8998\n",
      "Epoch 17/25, Training Loss: 0.2459, Training Accuracy: 0.9080, Training F1: 0.9075, Validation Loss: 0.2691, Validation Accuracy: 0.9008, Validation F1: 0.9022\n",
      "Epoch 18/25, Training Loss: 0.2409, Training Accuracy: 0.9111, Training F1: 0.9107, Validation Loss: 0.2905, Validation Accuracy: 0.8948, Validation F1: 0.8941\n",
      "Epoch 19/25, Training Loss: 0.2344, Training Accuracy: 0.9113, Training F1: 0.9108, Validation Loss: 0.2657, Validation Accuracy: 0.9003, Validation F1: 0.9016\n",
      "Epoch 20/25, Training Loss: 0.2295, Training Accuracy: 0.9153, Training F1: 0.9148, Validation Loss: 0.2830, Validation Accuracy: 0.8960, Validation F1: 0.8978\n",
      "Epoch 21/25, Training Loss: 0.2235, Training Accuracy: 0.9162, Training F1: 0.9158, Validation Loss: 0.2742, Validation Accuracy: 0.9027, Validation F1: 0.9044\n",
      "Epoch 22/25, Training Loss: 0.2198, Training Accuracy: 0.9176, Training F1: 0.9172, Validation Loss: 0.2772, Validation Accuracy: 0.9037, Validation F1: 0.9037\n",
      "Epoch 23/25, Training Loss: 0.2183, Training Accuracy: 0.9181, Training F1: 0.9176, Validation Loss: 0.2757, Validation Accuracy: 0.8983, Validation F1: 0.8999\n",
      "Epoch 24/25, Training Loss: 0.2133, Training Accuracy: 0.9200, Training F1: 0.9196, Validation Loss: 0.2747, Validation Accuracy: 0.9003, Validation F1: 0.9022\n",
      "Epoch 25/25, Training Loss: 0.2088, Training Accuracy: 0.9230, Training F1: 0.9226, Validation Loss: 0.2807, Validation Accuracy: 0.9007, Validation F1: 0.9030\n",
      "Test Loss: 0.2799, Test Accuracy: 0.8994, Test F1 Score: 0.9000\n",
      "  Training with learning rate: 0.0006\n",
      "Epoch 1/25, Training Loss: 0.5981, Training Accuracy: 0.7904, Training F1: 0.7883, Validation Loss: 0.3923, Validation Accuracy: 0.8563, Validation F1: 0.8588\n",
      "Epoch 2/25, Training Loss: 0.4394, Training Accuracy: 0.8428, Training F1: 0.8416, Validation Loss: 0.3428, Validation Accuracy: 0.8737, Validation F1: 0.8764\n",
      "Epoch 3/25, Training Loss: 0.3941, Training Accuracy: 0.8577, Training F1: 0.8567, Validation Loss: 0.3247, Validation Accuracy: 0.8777, Validation F1: 0.8786\n",
      "Epoch 4/25, Training Loss: 0.3721, Training Accuracy: 0.8653, Training F1: 0.8645, Validation Loss: 0.3095, Validation Accuracy: 0.8868, Validation F1: 0.8888\n",
      "Epoch 5/25, Training Loss: 0.3533, Training Accuracy: 0.8717, Training F1: 0.8709, Validation Loss: 0.3170, Validation Accuracy: 0.8797, Validation F1: 0.8803\n",
      "Epoch 6/25, Training Loss: 0.3370, Training Accuracy: 0.8775, Training F1: 0.8768, Validation Loss: 0.3007, Validation Accuracy: 0.8860, Validation F1: 0.8877\n",
      "Epoch 7/25, Training Loss: 0.3209, Training Accuracy: 0.8832, Training F1: 0.8825, Validation Loss: 0.3010, Validation Accuracy: 0.8865, Validation F1: 0.8852\n",
      "Epoch 8/25, Training Loss: 0.3124, Training Accuracy: 0.8849, Training F1: 0.8841, Validation Loss: 0.2979, Validation Accuracy: 0.8862, Validation F1: 0.8864\n",
      "Epoch 9/25, Training Loss: 0.3041, Training Accuracy: 0.8875, Training F1: 0.8868, Validation Loss: 0.2880, Validation Accuracy: 0.8930, Validation F1: 0.8933\n",
      "Epoch 10/25, Training Loss: 0.2931, Training Accuracy: 0.8925, Training F1: 0.8918, Validation Loss: 0.2888, Validation Accuracy: 0.8933, Validation F1: 0.8934\n",
      "Epoch 11/25, Training Loss: 0.2865, Training Accuracy: 0.8941, Training F1: 0.8934, Validation Loss: 0.2833, Validation Accuracy: 0.8895, Validation F1: 0.8901\n",
      "Epoch 12/25, Training Loss: 0.2803, Training Accuracy: 0.8973, Training F1: 0.8967, Validation Loss: 0.2883, Validation Accuracy: 0.8937, Validation F1: 0.8946\n",
      "Epoch 13/25, Training Loss: 0.2731, Training Accuracy: 0.8993, Training F1: 0.8986, Validation Loss: 0.2790, Validation Accuracy: 0.8957, Validation F1: 0.8971\n",
      "Epoch 14/25, Training Loss: 0.2642, Training Accuracy: 0.9026, Training F1: 0.9021, Validation Loss: 0.2763, Validation Accuracy: 0.8957, Validation F1: 0.8974\n",
      "Epoch 15/25, Training Loss: 0.2590, Training Accuracy: 0.9031, Training F1: 0.9026, Validation Loss: 0.2761, Validation Accuracy: 0.8953, Validation F1: 0.8969\n",
      "Epoch 16/25, Training Loss: 0.2523, Training Accuracy: 0.9070, Training F1: 0.9065, Validation Loss: 0.2925, Validation Accuracy: 0.8900, Validation F1: 0.8923\n",
      "Epoch 17/25, Training Loss: 0.2503, Training Accuracy: 0.9083, Training F1: 0.9078, Validation Loss: 0.2753, Validation Accuracy: 0.8980, Validation F1: 0.8985\n",
      "Epoch 18/25, Training Loss: 0.2428, Training Accuracy: 0.9104, Training F1: 0.9100, Validation Loss: 0.2865, Validation Accuracy: 0.8943, Validation F1: 0.8971\n",
      "Epoch 19/25, Training Loss: 0.2381, Training Accuracy: 0.9114, Training F1: 0.9109, Validation Loss: 0.2918, Validation Accuracy: 0.8910, Validation F1: 0.8902\n",
      "Epoch 20/25, Training Loss: 0.2345, Training Accuracy: 0.9134, Training F1: 0.9130, Validation Loss: 0.2736, Validation Accuracy: 0.9017, Validation F1: 0.9023\n",
      "Epoch 21/25, Training Loss: 0.2295, Training Accuracy: 0.9142, Training F1: 0.9139, Validation Loss: 0.2753, Validation Accuracy: 0.8940, Validation F1: 0.8945\n",
      "Epoch 22/25, Training Loss: 0.2288, Training Accuracy: 0.9163, Training F1: 0.9158, Validation Loss: 0.2698, Validation Accuracy: 0.9043, Validation F1: 0.9056\n",
      "Epoch 23/25, Training Loss: 0.2224, Training Accuracy: 0.9166, Training F1: 0.9162, Validation Loss: 0.2766, Validation Accuracy: 0.9008, Validation F1: 0.9025\n",
      "Epoch 24/25, Training Loss: 0.2178, Training Accuracy: 0.9171, Training F1: 0.9166, Validation Loss: 0.2729, Validation Accuracy: 0.9017, Validation F1: 0.9027\n",
      "Epoch 25/25, Training Loss: 0.2137, Training Accuracy: 0.9195, Training F1: 0.9190, Validation Loss: 0.2776, Validation Accuracy: 0.8967, Validation F1: 0.8990\n",
      "Test Loss: 0.2833, Test Accuracy: 0.8990, Test F1 Score: 0.8996\n",
      "*******************************************************************************************************************************\n",
      "\n",
      "Best Model:\n",
      "Architecture: Arch1\n",
      "Learning Rate: 0.001\n",
      "Test Accuracy: 0.9047\n",
      "Test F1 Score: 0.9050\n",
      "*******************************************************************************************************************************\n",
      "*******************************************************************************************************************************\n",
      "\n",
      "All Model Test Accuracies:\n",
      "Architecture: Arch1, Learning Rate: 0.005, Test Accuracy: 0.9042\n",
      "Architecture: Arch1, Learning Rate: 0.001, Test Accuracy: 0.9047\n",
      "Architecture: Arch1, Learning Rate: 0.0009, Test Accuracy: 0.9030\n",
      "Architecture: Arch1, Learning Rate: 0.0006, Test Accuracy: 0.9037\n",
      "Architecture: Arch2, Learning Rate: 0.005, Test Accuracy: 0.8974\n",
      "Architecture: Arch2, Learning Rate: 0.001, Test Accuracy: 0.9047\n",
      "Architecture: Arch2, Learning Rate: 0.0009, Test Accuracy: 0.8986\n",
      "Architecture: Arch2, Learning Rate: 0.0006, Test Accuracy: 0.8986\n",
      "Architecture: Arch3, Learning Rate: 0.005, Test Accuracy: 0.9030\n",
      "Architecture: Arch3, Learning Rate: 0.001, Test Accuracy: 0.9041\n",
      "Architecture: Arch3, Learning Rate: 0.0009, Test Accuracy: 0.8994\n",
      "Architecture: Arch3, Learning Rate: 0.0006, Test Accuracy: 0.8990\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model_results = []\n",
    "\n",
    "\n",
    "for arch_name, arch_info in architectures.items():\n",
    "    print(f\"\\nTraining models for architecture: {arch_name}\")\n",
    "    for lr in learning_rates:\n",
    "        print(f\"  Training with learning rate: {lr}\")\n",
    "        \n",
    "        # Build the network for the current configuration\n",
    "        layers = []\n",
    "        input_dim = 784  # 28x28 images flattened\n",
    "        for layer_info in arch_info['layers']:\n",
    "            units = layer_info['units']\n",
    "            \n",
    "            # Dense layer\n",
    "            layers.append(DenseLayer(input_dim, units))\n",
    "            layers.append(BatchNormalization(units))\n",
    "            layers.append(ReLU())\n",
    "            \n",
    "            # Apply dropout\n",
    "            layers.append(Dropout(dropout_rate))\n",
    "            \n",
    "            # Update input dimension for next layer\n",
    "            input_dim = units\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(DenseLayer(input_dim, num_classes))\n",
    "        \n",
    "        # Initialize the network\n",
    "        network = NeuralNetwork(layers)\n",
    "        \n",
    "        # Train the model and capture metrics\n",
    "        train_losses, val_losses, train_accuracies, val_accuracies, train_f1s, val_f1s = train(\n",
    "            network, X_train, y_train_one_hot, X_val, y_val_one_hot, num_epochs, batch_size, lr\n",
    "        )\n",
    "        \n",
    "        # Evaluate on the test set\n",
    "        test_loss, test_accuracy, test_f1 = evaluate(network, X_test, y_test_one_hot)\n",
    "        \n",
    "        # Log the results\n",
    "        model_info = {\n",
    "            'architecture': arch_name,\n",
    "            'learning_rate': lr,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'train_accuracies': train_accuracies,\n",
    "            'val_accuracies': val_accuracies,\n",
    "            'train_f1s': train_f1s,\n",
    "            'val_f1s': val_f1s,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'test_f1': test_f1,\n",
    "        }\n",
    "        model_results.append(model_info)\n",
    "\n",
    "        generate_confusion_matrix(network, X_test, y_test, arch_name, lr)\n",
    "        \n",
    "        # Check if this model is the best so far\n",
    "        if test_accuracy > best_test_accuracy:\n",
    "            best_test_accuracy = test_accuracy\n",
    "            best_model = network\n",
    "            best_model_info = model_info\n",
    "        \n",
    "        # Generate and save plots for this model\n",
    "        plot_metrics(\n",
    "            arch_name, lr, train_losses, val_losses,\n",
    "            train_accuracies, val_accuracies, train_f1s, val_f1s\n",
    "        )\n",
    "\n",
    "# Save the best model using pickle\n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(\"*******************************************************************************************************************************\")\n",
    "print(\"\\nBest Model:\")\n",
    "print(f\"Architecture: {best_model_info['architecture']}\")\n",
    "print(f\"Learning Rate: {best_model_info['learning_rate']}\")\n",
    "print(f\"Test Accuracy: {best_model_info['test_accuracy']:.4f}\")\n",
    "print(f\"Test F1 Score: {best_model_info['test_f1']:.4f}\")\n",
    "print(\"*******************************************************************************************************************************\")\n",
    "\n",
    "\n",
    "plot_metrics(\n",
    "    best_model_info['architecture'],\n",
    "    best_model_info['learning_rate'],\n",
    "    best_model_info['train_losses'],\n",
    "    best_model_info['val_losses'],\n",
    "    best_model_info['train_accuracies'],\n",
    "    best_model_info['val_accuracies'],\n",
    "    best_model_info['train_f1s'],\n",
    "    best_model_info['val_f1s']\n",
    ")\n",
    "\n",
    "# Generate confusion matrix for the best model with appropriate filename\n",
    "generate_confusion_matrix(best_model, X_test, y_test, best_model_info['architecture'], best_model_info['learning_rate'])\n",
    "\n",
    "\n",
    "# Log all test accuracies\n",
    "print(\"*******************************************************************************************************************************\")\n",
    "print(\"\\nAll Model Test Accuracies:\")\n",
    "for info in model_results:\n",
    "    print(f\"Architecture: {info['architecture']}, Learning Rate: {info['learning_rate']}, \"\n",
    "          f\"Test Accuracy: {info['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    model_params = {}\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        if isinstance(layer, DenseLayer):\n",
    "            model_params[f'weight_{idx}'] = layer.W\n",
    "            model_params[f'bias_{idx}'] = layer.b\n",
    "    with open(filepath, 'wb') as file:\n",
    "        pickle.dump(model_params, file)\n",
    "\n",
    "save_model(best_model, 'best_model_str.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the best model and predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9047\n",
      "Test F1 Score: 0.9050\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "with open('best_model.pkl', 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "\n",
    "def evaluate_loaded_model(model, X_test, y_test_one_hot):\n",
    "    \n",
    "    logits = model.forward(X_test, training=False)\n",
    "    \n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    true_labels = np.argmax(y_test_one_hot, axis=1)\n",
    "    \n",
    "    test_accuracy = accuracy_score(true_labels, predictions)\n",
    "    test_f1 = f1_score(true_labels, predictions, average='macro')\n",
    "    \n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=range(10), yticklabels=range(10))\n",
    "    plt.title('Confusion Matrix for Best Model')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "evaluate_loaded_model(best_model, X_test, y_test_one_hot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
